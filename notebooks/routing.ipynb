{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import sys; sys.path.append(\"..\")\n",
    "\n",
    "import ray\n",
    "\n",
    "from app.config import ROOT_DIR\n",
    "from app.util import stratify_split\n",
    "\n",
    "with open(Path(ROOT_DIR, \"experiments/evaluations/gpt-4/llama-2-70b-gtebase.json\")) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 21:17:12,693\tINFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.0.41.167:6379...\n",
      "2023-08-30 21:17:12,700\tINFO worker.py:1612 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-iq4d2ux1mdavtyqs5xdnlk2vcv.i.anyscaleuserdata-staging.com \u001b[39m\u001b[22m\n",
      "2023-08-30 21:17:12,703\tINFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_aa5eb8d5da2d1d69c8f39ffa7a820268.zip' (0.38MiB) to Ray cluster...\n",
      "2023-08-30 21:17:12,704\tINFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_aa5eb8d5da2d1d69c8f39ffa7a820268.zip'.\n",
      "2023-08-30 21:17:12,938\tINFO dataset.py:2357 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'I’m struggling a bit with Ray Data type conversions when I do map_batches. Any advice?', 'targets': 1}\n",
      "{'question': 'How does autoscaling work in a Ray Serve application?', 'targets': 1}\n",
      "{'question': 'can i create my own ray image with custom python version', 'targets': 0}\n",
      "{'question': 'how do I get the address of a ray node', 'targets': 0}\n",
      "{'question': 'are you based on GPT-4?', 'targets': 1}\n",
      "{'question': 'why it takes 10 mins for you to answer my question?', 'targets': 0}\n",
      "{'question': 'Does Ray support NCCL?', 'targets': 0}\n",
      "{'question': 'could you give me an example of using this library for data-parallel training of CNNs on Ray?', 'targets': 0}\n",
      "{'question': 'Is Ray integrated with DeepSpeed?', 'targets': 0}\n",
      "{'question': \"what will happen if I use AsyncIO's await to wait for a Ray future like `await x.remote()`\", 'targets': 0}\n",
      "{'question': 'How would you compare Spark, Ray, Dask?', 'targets': 0}\n",
      "{'question': 'why would ray overload a node w/ more task that the resources allow ?', 'targets': 1}\n",
      "{'question': 'when should I use Ray Client?', 'targets': 1}\n",
      "{'question': 'how to scatter actors across the cluster?', 'targets': 1}\n",
      "{'question': 'how can i go about fine tuning a LLM with Ray?', 'targets': 0}\n",
      "{'question': 'can you create a tweet thread from chapter 8, \"Online Inference with Ray Serve\" of the book \"Learning Ray\"?', 'targets': 1}\n",
      "{'question': \"On remote ray cluster, when I do `ray debug` I'm getting connection refused error. Why ?\", 'targets': 0}\n",
      "{'question': 'How does Ray AIR set up the model to communicate gradient updates across machines?', 'targets': 0}\n",
      "{'question': \"Why would I use Ray Serve instead of Modal or Seldon? Why can't I just do it via containers?\", 'targets': 1}\n",
      "{'question': 'How do I deploy an LLM workload on top of Ray Serve?', 'targets': 0}\n"
     ]
    }
   ],
   "source": [
    "ds = ray.data.from_items([{\"question\": result[\"question\"], \"targets\": 0 if result[\"score\"] < 4 else 1} for result in data[\"results\"]])\n",
    "train_ds, val_ds = stratify_split(ds, stratify=\"targets\", test_size=0.3)\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'how can I use leela chess zero for a similar two player board game called breakthrough?', 'targets': 1}\n",
      "{'question': 'what is num_samples in tune?', 'targets': 1}\n",
      "{'question': \"What's the difference between learner worker and local worker?\", 'targets': 1}\n",
      "{'question': 'I have a two player board game that I would like to learn by self-play using alphazero. How can I do this', 'targets': 1}\n",
      "{'question': 'if I am inside of a anyscale cluster how do I get my cluster-env-build-id', 'targets': 0}\n",
      "{'question': 'how do I run a task in ray?', 'targets': 1}\n",
      "{'question': 'how to use ray to do distributed xgboost training on k8s', 'targets': 1}\n",
      "{'question': \"Is there a way to send work to Ray where the head worker doesn't execute the job, only the workers?\", 'targets': 1}\n",
      "{'question': \"I'm trying to write a policy which randomly chooses only from the valid actions. In my environment's observations, I list the valid actions in an array of bools. By the time it reaches my policy's compute_actions_from_input_dict the observations have been flattened so I don't know where my action_mask is. How can I identify it?\", 'targets': 1}\n",
      "{'question': 'how to plot ray train loss ?', 'targets': 1}\n",
      "{'question': 'I have a gymnasium environment that outputs observations of size(210,) float32 and takes discrete(3) actions.', 'targets': 1}\n",
      "{'question': 'Where can I import PolicySpec from?', 'targets': 0}\n",
      "{'question': 'how to launch ray head with docker image?', 'targets': 1}\n",
      "{'question': 'how to launch ray cluster with docker image manually?', 'targets': 1}\n",
      "{'question': 'What about boot_disk_size_gb', 'targets': 0}\n",
      "{'question': 'what should be the number for replica_count ? does this vary depending on cpu count ?', 'targets': 1}\n",
      "{'question': 'how does deployment graphic step 1 pass data to step2?', 'targets': 1}\n",
      "{'question': 'Can I run a request on aws', 'targets': 1}\n",
      "{'question': 'How do I set up iterative self-play training?', 'targets': 1}\n",
      "{'question': 'What is the name if I deploy twice the same class ?', 'targets': 1}\n"
     ]
    }
   ],
   "source": [
    "with open(Path(ROOT_DIR, \"datasets\", \"routing.json\")) as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "ds = ray.data.from_items(dataset)\n",
    "train_ds, val_ds = stratify_split(ds, stratify=\"targets\", test_size=0.3)\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be81ab2b6274f58bcc05e125c22f452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473bf4d27a8646119ba951f20efef95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = BertModel.from_pretrained(\"bert-base-uncased\", return_dict=False)\n",
    "embedding_dim = llm.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", return_dict=False)\n",
    "text = \"Transfer learning with transformers for text classification.\"\n",
    "batch = tokenizer([text], return_tensors=\"np\", padding=\"longest\")\n",
    "batch = {k: torch.tensor(v) for k, v in batch.items()}  # convert to torch tensors\n",
    "seq, pool = llm(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"])\n",
    "np.shape(seq), np.shape(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinetunedLLM(nn.Module):\n",
    "    def __init__(self, llm, dropout_p, embedding_dim, num_classes):\n",
    "        super(FinetunedLLM, self).__init__()\n",
    "        self.llm = llm\n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "        self.fc1 = torch.nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ids, masks = batch[\"ids\"], batch[\"masks\"]\n",
    "        seq, pool = self.llm(input_ids=ids, attention_mask=masks)\n",
    "        z = self.dropout(pool)\n",
    "        z = self.fc1(z)\n",
    "        return z\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def predict(self, batch):\n",
    "        self.eval()\n",
    "        z = self(inputs)\n",
    "        y_pred = torch.argmax(z, dim=1).cpu().numpy()\n",
    "        return y_pred\n",
    "    \n",
    "    @torch.inference_mode()\n",
    "    def predict_proba(self, batch):\n",
    "        self.eval()\n",
    "        z = self(batch)\n",
    "        y_probs = F.softmax(z).cpu().numpy()\n",
    "        return y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.named_parameters of FinetunedLLM(\n",
      "  (llm): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=768, out_features=2, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "model = FinetunedLLM(llm=llm, dropout_p=0.5, embedding_dim=embedding_dim, num_classes=2)\n",
    "print (model.named_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 21:17:37,494\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Sort] -> AllToAllOperator[MapBatches(group_fn)->MapBatches(_filter_split)->RandomShuffle] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "2023-08-30 21:17:37,495\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-08-30 21:17:37,495\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bb28e592b84c84bfd49597adf69a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eefa28686ecb46c0a7664505ddf59265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c120b01fb8740a98db27057e698040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63c4b43feea44109ffde06a3dcb94fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee208e2e626421cabeae7c97ce41422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(group_fn)->MapBatches(_filter_split)->RandomShuffle 5:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d1786a89d64d63a8de59fe853b5344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 6:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ce0ce25c0d47b6bb6f2ed23bff9a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 7:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db9988bdf854ebca48a9e4694fc4f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e482d221287b4b6caeca688337d8ba76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 7.45MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 8.59kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(batch):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", return_dict=False)\n",
    "    encoded_inputs = tokenizer(batch[\"question\"].tolist(), return_tensors=\"np\", padding=\"longest\")\n",
    "    return {\"ids\": encoded_inputs[\"input_ids\"], \"masks\": encoded_inputs[\"attention_mask\"], \"targets\": batch[\"targets\"]}\n",
    "\n",
    "train_ds = train_ds.map_batches(preprocess)\n",
    "val_ds = val_ds.map_batches(preprocess)\n",
    "\n",
    "train_ds.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.train.torch import get_device\n",
    "\n",
    "def pad_array(arr, dtype=np.int32):\n",
    "    max_len = max(len(row) for row in arr)\n",
    "    padded_arr = np.zeros((arr.shape[0], max_len), dtype=dtype)\n",
    "    for i, row in enumerate(arr):\n",
    "        padded_arr[i][:len(row)] = row\n",
    "    return padded_arr\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batch[\"ids\"] = pad_array(batch[\"ids\"])\n",
    "    batch[\"masks\"] = pad_array(batch[\"masks\"])\n",
    "    dtypes = {\"ids\": torch.int32, \"masks\": torch.int32, \"targets\": torch.int64}\n",
    "    tensor_batch = {}\n",
    "    for key, array in batch.items():\n",
    "        tensor_batch[key] = torch.as_tensor(array, dtype=dtypes[key], device=get_device())\n",
    "    return tensor_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train\n",
    "from ray.train import Checkpoint, CheckpointConfig, DataConfig, RunConfig, ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(ds, batch_size, model, num_classes, loss_fn, optimizer):\n",
    "    \"\"\"Train step.\"\"\"\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    for i, batch in enumerate(ds_generator):\n",
    "        optimizer.zero_grad()  # reset gradients\n",
    "        z = model(batch)  # forward pass\n",
    "        targets = F.one_hot(batch[\"targets\"], num_classes=num_classes).float()  # one-hot (for loss_fn)\n",
    "        J = loss_fn(z, targets)  # define loss\n",
    "        J.backward()  # backward pass\n",
    "        optimizer.step()  # update weights\n",
    "        loss += (J.detach().item() - loss) / (i + 1)  # cumulative loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(ds, batch_size, model, num_classes, loss_fn):\n",
    "    \"\"\"Eval step.\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    y_trues, y_preds = [], []\n",
    "    ds_generator = ds.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    with torch.inference_mode():\n",
    "        for i, batch in enumerate(ds_generator):\n",
    "            z = model(batch)\n",
    "            targets = F.one_hot(batch[\"targets\"], num_classes=num_classes).float()  # one-hot (for loss_fn)\n",
    "            J = loss_fn(z, targets).item()\n",
    "            loss += (J - loss) / (i + 1)\n",
    "            y_trues.extend(batch[\"targets\"].cpu().numpy())\n",
    "            y_preds.extend(torch.argmax(z, dim=1).cpu().numpy())\n",
    "    return loss, np.vstack(y_trues), np.vstack(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_func(config):\n",
    "    # Hyperparameters\n",
    "    dropout_p = config[\"dropout_p\"]\n",
    "    lr = config[\"lr\"]\n",
    "    lr_factor = config[\"lr_factor\"]\n",
    "    lr_patience = config[\"lr_patience\"]\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    num_classes = config[\"num_classes\"]\n",
    "\n",
    "    # Get datasets\n",
    "    # set_seeds()\n",
    "    train_ds = train.get_dataset_shard(\"train\")\n",
    "    val_ds = train.get_dataset_shard(\"val\")\n",
    "\n",
    "    # Model\n",
    "    llm = BertModel.from_pretrained(\"allenai/scibert_scivocab_uncased\", return_dict=False)\n",
    "    model = FinetunedLLM(llm=llm, dropout_p=dropout_p, embedding_dim=llm.config.hidden_size, num_classes=num_classes)\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    # Training components\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=lr_factor, patience=lr_patience)\n",
    "\n",
    "    # Training\n",
    "    batch_size_per_worker = batch_size // train.get_context().get_world_size()\n",
    "    for epoch in range(num_epochs):\n",
    "        # Step\n",
    "        train_loss = train_step(train_ds, batch_size_per_worker, model, num_classes, loss_fn, optimizer)\n",
    "        val_loss, _, _ = eval_step(val_ds, batch_size_per_worker, model, num_classes, loss_fn)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Checkpoint\n",
    "        metrics = dict(epoch=epoch, lr=optimizer.param_groups[0][\"lr\"], train_loss=train_loss, val_loss=val_loss)\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            torch.save(model.state_dict(), os.path.join(tmpdir, \"model.pt\"))\n",
    "            train.report(metrics, checkpoint=Checkpoint.from_directory(tmpdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop config\n",
    "train_loop_config = {\n",
    "    \"dropout_p\": 0.5,\n",
    "    \"lr\": 1e-5,\n",
    "    \"lr_factor\": 0.8,\n",
    "    \"lr_patience\": 3,\n",
    "    \"num_epochs\": 30,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_classes\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling config\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=1,\n",
    "    use_gpu=True,\n",
    "    resources_per_worker={\"CPU\": 10, \"GPU\": 1},\n",
    "    _max_cpu_fraction_per_node=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/ray/air/config.py:806: UserWarning: Setting a `RunConfig.local_dir` is deprecated and will be removed in the future. If you are not using remote storage,set the `RunConfig.storage_path` instead. Otherwise, set the`RAY_AIR_LOCAL_CACHE_DIR` environment variable to control the local cache location.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run config\n",
    "checkpoint_config = CheckpointConfig(num_to_keep=1, checkpoint_score_attribute=\"val_loss\", checkpoint_score_order=\"min\")\n",
    "run_config = RunConfig(name=\"llm\", checkpoint_config=checkpoint_config, local_dir=\"~/ray_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 21:18:12,198\tINFO streaming_executor.py:93 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Sort] -> AllToAllOperator[MapBatches(group_fn)->MapBatches(_filter_split)->RandomShuffle] -> TaskPoolMapOperator[MapBatches(preprocess)]\n",
      "2023-08-30 21:18:12,199\tINFO streaming_executor.py:94 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2023-08-30 21:18:12,199\tINFO streaming_executor.py:96 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea7d9ba58764749bf957ce0eda50612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 1:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefec0c9b8c54a3f9ba15936e49018f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 2:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e039a3b3524e6abe4a65e630412ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7ad1338878491c884d80f9bdd8f687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34984759c95e440286717a91102187ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(group_fn)->MapBatches(_filter_split)->RandomShuffle 5:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056694f5c69547a48aec8a37d09fa26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 6:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5096e552b6d5454da444c03a63eb1cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 7:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b90e20faec4f1fa23de09a3b296c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f460eb290a0485f97ff17baf1fe415d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = TorchTrainer(\n",
    "    train_func,\n",
    "    train_loop_config=train_loop_config,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    datasets={\"train\": train_ds.materialize(), \"val\": val_ds.materialize()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-30 21:20:47</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:24.02        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.8/62.1 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 11.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A10G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc             </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  train_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_6cb07_00000</td><td>TERMINATED</td><td>10.0.41.167:6798</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">          138.48</td><td style=\"text-align: right;\">     29</td><td style=\"text-align: right;\">2.09715e-06</td><td style=\"text-align: right;\">   0.0638379</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=6798)\u001b[0m Starting distributed worker processes: ['6893 (10.0.41.167)']\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6893)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 385/385 [00:00<00:00, 118kB/s]\n",
      "Downloading pytorch_model.bin:   0%|          | 0.00/442M [00:00<?, ?B/s]\n",
      "Downloading pytorch_model.bin:   2%|▏         | 10.5M/442M [00:00<00:07, 60.1MB/s]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Auto configuring locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e']\n",
      "Downloading pytorch_model.bin:   9%|▉         | 41.9M/442M [00:00<00:02, 153MB/s] \n",
      "Downloading pytorch_model.bin:  17%|█▋        | 73.4M/442M [00:00<00:01, 188MB/s]\n",
      "Downloading pytorch_model.bin:  24%|██▎       | 105M/442M [00:00<00:01, 207MB/s] \n",
      "Downloading pytorch_model.bin:  31%|███       | 136M/442M [00:00<00:01, 217MB/s]\n",
      "Downloading pytorch_model.bin:  38%|███▊      | 168M/442M [00:00<00:01, 225MB/s]\n",
      "Downloading pytorch_model.bin:  45%|████▌     | 199M/442M [00:00<00:01, 229MB/s]\n",
      "Downloading pytorch_model.bin:  52%|█████▏    | 231M/442M [00:01<00:00, 230MB/s]\n",
      "Downloading pytorch_model.bin:  59%|█████▉    | 262M/442M [00:01<00:00, 232MB/s]\n",
      "Downloading pytorch_model.bin:  66%|██████▋   | 294M/442M [00:01<00:00, 233MB/s]\n",
      "Downloading pytorch_model.bin:  74%|███████▎  | 325M/442M [00:01<00:00, 233MB/s]\n",
      "Downloading pytorch_model.bin:  81%|████████  | 357M/442M [00:01<00:00, 234MB/s]\n",
      "Downloading pytorch_model.bin:  88%|████████▊ | 388M/442M [00:01<00:00, 234MB/s]\n",
      "Downloading pytorch_model.bin:  95%|█████████▍| 419M/442M [00:01<00:00, 235MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 442M/442M [00:02<00:00, 220MB/s]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6893)\u001b[0m Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=6893)\u001b[0m /tmp/ipykernel_4958/827826225.py:16: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94060c7dcc724f5493a83fbe9cc74595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7487c514d62a4c83a6fdabecb26ea17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fe4ab917904e24bfdd30d73382b5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875a8a8f02c24b75b6470ca993f99155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90ab9eb4945485e8eb58886fccefcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae7a0b8f8464a08a5866e4ea26207a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dcf9d517b54c3894ee03d5749ab0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e87fd19625d44c095f2255eb4d6908b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a7033fa7140c5b57e1750ee4ed23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1a2ae15f7e48acab05a51bd83e70bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce786e3d08744b33bcb3c52756aecd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e13cd4ccaa477aaa5ccb805c454788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d5f6330578427eac8dd9b01fafa7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43956353c9064e45aad3736a3cdcd6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857bc06ca8e940eb886551d625a186ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c6234462534b598fe0b31f6e887a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbb12ec09f54777b5841c1e72145c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b54f2847984d6f8d0ae6693c0f21eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d16bac4b7c4dac913f2a1b14708383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0770e4f27cc4bd98650e3d2c707aadc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12ba24e64374f99848d306baa63cf34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3b082650a0428b937b9b07f981e2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1636021565804a3cb783f53d98c9c65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a41c323aec417d85d97bd82a1279d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a2e758c1114077b8efc0f31090b3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f8cf9f4b21414ea02fb6ebf778ebeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297c1a7a77684374b8d2272e7ee3e59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3695eaa87c564abda2b776059b7c5b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1e5df354ff40a9a1bd354bd1b67385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Executing DAG InputDataBuffer[Input] -> OutputSplitter[split(1, equal=True)]\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=2000000000.0), locality_with_output=['f345f4a29a524c2dda718e763a8b6278b481b372979fd2d18f46080e'], preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "\u001b[2m\u001b[36m(SplitCoordinator pid=6984)\u001b[0m Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e0a2d487cc43de9d7baac47108e404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=6984) Running 0:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-30 21:20:47,468\tINFO tune.py:1146 -- Total run time: 144.20 seconds (144.01 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.84 s, sys: 1.75 s, total: 5.59 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train\n",
    "results = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.549363</td>\n",
       "      <td>0.518476</td>\n",
       "      <td>1693455518</td>\n",
       "      <td>12.171986</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-18-38</td>\n",
       "      <td>12.171986</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>12.171986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.502609</td>\n",
       "      <td>0.519532</td>\n",
       "      <td>1693455522</td>\n",
       "      <td>4.334957</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-18-43</td>\n",
       "      <td>16.506943</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>16.506943</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.500884</td>\n",
       "      <td>0.518813</td>\n",
       "      <td>1693455527</td>\n",
       "      <td>4.319682</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-18-47</td>\n",
       "      <td>20.826625</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>20.826625</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.493299</td>\n",
       "      <td>0.524068</td>\n",
       "      <td>1693455531</td>\n",
       "      <td>4.372862</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-18-51</td>\n",
       "      <td>25.199487</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>25.199487</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.482310</td>\n",
       "      <td>0.529211</td>\n",
       "      <td>1693455536</td>\n",
       "      <td>4.328253</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-18-56</td>\n",
       "      <td>29.527740</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>29.527740</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.486419</td>\n",
       "      <td>0.539902</td>\n",
       "      <td>1693455540</td>\n",
       "      <td>4.366602</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-00</td>\n",
       "      <td>33.894342</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>33.894342</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.468147</td>\n",
       "      <td>0.529105</td>\n",
       "      <td>1693455544</td>\n",
       "      <td>4.359318</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-04</td>\n",
       "      <td>38.253660</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>38.253660</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.461753</td>\n",
       "      <td>0.541340</td>\n",
       "      <td>1693455549</td>\n",
       "      <td>4.350897</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-09</td>\n",
       "      <td>42.604557</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>42.604557</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.430996</td>\n",
       "      <td>0.565780</td>\n",
       "      <td>1693455553</td>\n",
       "      <td>4.348210</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-13</td>\n",
       "      <td>46.952767</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>46.952767</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.423773</td>\n",
       "      <td>0.574876</td>\n",
       "      <td>1693455557</td>\n",
       "      <td>4.340979</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-17</td>\n",
       "      <td>51.293746</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>51.293746</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.383039</td>\n",
       "      <td>0.592022</td>\n",
       "      <td>1693455562</td>\n",
       "      <td>4.378277</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-22</td>\n",
       "      <td>55.672023</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>55.672023</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.360481</td>\n",
       "      <td>0.643280</td>\n",
       "      <td>1693455566</td>\n",
       "      <td>4.365991</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-26</td>\n",
       "      <td>60.038014</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>60.038014</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.320649</td>\n",
       "      <td>0.695383</td>\n",
       "      <td>1693455570</td>\n",
       "      <td>4.358274</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-30</td>\n",
       "      <td>64.396288</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>64.396288</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.728476</td>\n",
       "      <td>1693455575</td>\n",
       "      <td>4.380119</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-35</td>\n",
       "      <td>68.776407</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>68.776407</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.267625</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>1693455579</td>\n",
       "      <td>4.385803</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-39</td>\n",
       "      <td>73.162210</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>73.162210</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.267642</td>\n",
       "      <td>0.778585</td>\n",
       "      <td>1693455583</td>\n",
       "      <td>4.350595</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-44</td>\n",
       "      <td>77.512805</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>77.512805</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.201532</td>\n",
       "      <td>0.766891</td>\n",
       "      <td>1693455588</td>\n",
       "      <td>4.355030</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-48</td>\n",
       "      <td>81.867835</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>81.867835</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.849883</td>\n",
       "      <td>1693455592</td>\n",
       "      <td>4.329851</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-52</td>\n",
       "      <td>86.197686</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>86.197686</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.167858</td>\n",
       "      <td>0.829767</td>\n",
       "      <td>1693455597</td>\n",
       "      <td>4.332349</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-19-57</td>\n",
       "      <td>90.530035</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>90.530035</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.145448</td>\n",
       "      <td>0.843916</td>\n",
       "      <td>1693455601</td>\n",
       "      <td>4.323631</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-01</td>\n",
       "      <td>94.853667</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>94.853667</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.120539</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>1693455605</td>\n",
       "      <td>4.416107</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-05</td>\n",
       "      <td>99.269773</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>99.269773</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.109817</td>\n",
       "      <td>0.895535</td>\n",
       "      <td>1693455610</td>\n",
       "      <td>4.349299</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-10</td>\n",
       "      <td>103.619072</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>103.619072</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.080894</td>\n",
       "      <td>0.941536</td>\n",
       "      <td>1693455614</td>\n",
       "      <td>4.386154</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-14</td>\n",
       "      <td>108.005226</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>108.005226</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.077071</td>\n",
       "      <td>0.953890</td>\n",
       "      <td>1693455618</td>\n",
       "      <td>4.339841</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-18</td>\n",
       "      <td>112.345067</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>112.345067</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.079360</td>\n",
       "      <td>0.994520</td>\n",
       "      <td>1693455623</td>\n",
       "      <td>4.334562</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-23</td>\n",
       "      <td>116.679629</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>116.679629</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.069954</td>\n",
       "      <td>0.980493</td>\n",
       "      <td>1693455627</td>\n",
       "      <td>4.347502</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-27</td>\n",
       "      <td>121.027131</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>121.027131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.965959</td>\n",
       "      <td>1693455631</td>\n",
       "      <td>4.377449</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-31</td>\n",
       "      <td>125.404580</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>125.404580</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.065896</td>\n",
       "      <td>1.012560</td>\n",
       "      <td>1693455636</td>\n",
       "      <td>4.376288</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>28</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-36</td>\n",
       "      <td>129.780868</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>129.780868</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.983981</td>\n",
       "      <td>1693455640</td>\n",
       "      <td>4.357719</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-40</td>\n",
       "      <td>134.138587</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>134.138587</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.063838</td>\n",
       "      <td>0.977269</td>\n",
       "      <td>1693455644</td>\n",
       "      <td>4.341392</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>6cb07_00000</td>\n",
       "      <td>2023-08-30_21-20-45</td>\n",
       "      <td>138.479979</td>\n",
       "      <td>6798</td>\n",
       "      <td>ip-10-0-41-167</td>\n",
       "      <td>10.0.41.167</td>\n",
       "      <td>138.479979</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch        lr  train_loss  val_loss   timestamp  time_this_iter_s  \\\n",
       "0       0  0.000010    0.549363  0.518476  1693455518         12.171986   \n",
       "1       1  0.000010    0.502609  0.519532  1693455522          4.334957   \n",
       "2       2  0.000010    0.500884  0.518813  1693455527          4.319682   \n",
       "3       3  0.000010    0.493299  0.524068  1693455531          4.372862   \n",
       "4       4  0.000008    0.482310  0.529211  1693455536          4.328253   \n",
       "5       5  0.000008    0.486419  0.539902  1693455540          4.366602   \n",
       "6       6  0.000008    0.468147  0.529105  1693455544          4.359318   \n",
       "7       7  0.000008    0.461753  0.541340  1693455549          4.350897   \n",
       "8       8  0.000006    0.430996  0.565780  1693455553          4.348210   \n",
       "9       9  0.000006    0.423773  0.574876  1693455557          4.340979   \n",
       "10     10  0.000006    0.383039  0.592022  1693455562          4.378277   \n",
       "11     11  0.000006    0.360481  0.643280  1693455566          4.365991   \n",
       "12     12  0.000005    0.320649  0.695383  1693455570          4.358274   \n",
       "13     13  0.000005    0.276786  0.728476  1693455575          4.380119   \n",
       "14     14  0.000005    0.267625  0.755906  1693455579          4.385803   \n",
       "15     15  0.000005    0.267642  0.778585  1693455583          4.350595   \n",
       "16     16  0.000004    0.201532  0.766891  1693455588          4.355030   \n",
       "17     17  0.000004    0.179633  0.849883  1693455592          4.329851   \n",
       "18     18  0.000004    0.167858  0.829767  1693455597          4.332349   \n",
       "19     19  0.000004    0.145448  0.843916  1693455601          4.323631   \n",
       "20     20  0.000003    0.120539  0.879357  1693455605          4.416107   \n",
       "21     21  0.000003    0.109817  0.895535  1693455610          4.349299   \n",
       "22     22  0.000003    0.080894  0.941536  1693455614          4.386154   \n",
       "23     23  0.000003    0.077071  0.953890  1693455618          4.339841   \n",
       "24     24  0.000003    0.079360  0.994520  1693455623          4.334562   \n",
       "25     25  0.000003    0.069954  0.980493  1693455627          4.347502   \n",
       "26     26  0.000003    0.054496  0.965959  1693455631          4.377449   \n",
       "27     27  0.000003    0.065896  1.012560  1693455636          4.376288   \n",
       "28     28  0.000002    0.053800  0.983981  1693455640          4.357719   \n",
       "29     29  0.000002    0.063838  0.977269  1693455644          4.341392   \n",
       "\n",
       "    should_checkpoint   done  training_iteration     trial_id  \\\n",
       "0                True  False                   1  6cb07_00000   \n",
       "1                True  False                   2  6cb07_00000   \n",
       "2                True  False                   3  6cb07_00000   \n",
       "3                True  False                   4  6cb07_00000   \n",
       "4                True  False                   5  6cb07_00000   \n",
       "5                True  False                   6  6cb07_00000   \n",
       "6                True  False                   7  6cb07_00000   \n",
       "7                True  False                   8  6cb07_00000   \n",
       "8                True  False                   9  6cb07_00000   \n",
       "9                True  False                  10  6cb07_00000   \n",
       "10               True  False                  11  6cb07_00000   \n",
       "11               True  False                  12  6cb07_00000   \n",
       "12               True  False                  13  6cb07_00000   \n",
       "13               True  False                  14  6cb07_00000   \n",
       "14               True  False                  15  6cb07_00000   \n",
       "15               True  False                  16  6cb07_00000   \n",
       "16               True  False                  17  6cb07_00000   \n",
       "17               True  False                  18  6cb07_00000   \n",
       "18               True  False                  19  6cb07_00000   \n",
       "19               True  False                  20  6cb07_00000   \n",
       "20               True  False                  21  6cb07_00000   \n",
       "21               True  False                  22  6cb07_00000   \n",
       "22               True  False                  23  6cb07_00000   \n",
       "23               True  False                  24  6cb07_00000   \n",
       "24               True  False                  25  6cb07_00000   \n",
       "25               True  False                  26  6cb07_00000   \n",
       "26               True  False                  27  6cb07_00000   \n",
       "27               True  False                  28  6cb07_00000   \n",
       "28               True  False                  29  6cb07_00000   \n",
       "29               True  False                  30  6cb07_00000   \n",
       "\n",
       "                   date  time_total_s   pid        hostname      node_ip  \\\n",
       "0   2023-08-30_21-18-38     12.171986  6798  ip-10-0-41-167  10.0.41.167   \n",
       "1   2023-08-30_21-18-43     16.506943  6798  ip-10-0-41-167  10.0.41.167   \n",
       "2   2023-08-30_21-18-47     20.826625  6798  ip-10-0-41-167  10.0.41.167   \n",
       "3   2023-08-30_21-18-51     25.199487  6798  ip-10-0-41-167  10.0.41.167   \n",
       "4   2023-08-30_21-18-56     29.527740  6798  ip-10-0-41-167  10.0.41.167   \n",
       "5   2023-08-30_21-19-00     33.894342  6798  ip-10-0-41-167  10.0.41.167   \n",
       "6   2023-08-30_21-19-04     38.253660  6798  ip-10-0-41-167  10.0.41.167   \n",
       "7   2023-08-30_21-19-09     42.604557  6798  ip-10-0-41-167  10.0.41.167   \n",
       "8   2023-08-30_21-19-13     46.952767  6798  ip-10-0-41-167  10.0.41.167   \n",
       "9   2023-08-30_21-19-17     51.293746  6798  ip-10-0-41-167  10.0.41.167   \n",
       "10  2023-08-30_21-19-22     55.672023  6798  ip-10-0-41-167  10.0.41.167   \n",
       "11  2023-08-30_21-19-26     60.038014  6798  ip-10-0-41-167  10.0.41.167   \n",
       "12  2023-08-30_21-19-30     64.396288  6798  ip-10-0-41-167  10.0.41.167   \n",
       "13  2023-08-30_21-19-35     68.776407  6798  ip-10-0-41-167  10.0.41.167   \n",
       "14  2023-08-30_21-19-39     73.162210  6798  ip-10-0-41-167  10.0.41.167   \n",
       "15  2023-08-30_21-19-44     77.512805  6798  ip-10-0-41-167  10.0.41.167   \n",
       "16  2023-08-30_21-19-48     81.867835  6798  ip-10-0-41-167  10.0.41.167   \n",
       "17  2023-08-30_21-19-52     86.197686  6798  ip-10-0-41-167  10.0.41.167   \n",
       "18  2023-08-30_21-19-57     90.530035  6798  ip-10-0-41-167  10.0.41.167   \n",
       "19  2023-08-30_21-20-01     94.853667  6798  ip-10-0-41-167  10.0.41.167   \n",
       "20  2023-08-30_21-20-05     99.269773  6798  ip-10-0-41-167  10.0.41.167   \n",
       "21  2023-08-30_21-20-10    103.619072  6798  ip-10-0-41-167  10.0.41.167   \n",
       "22  2023-08-30_21-20-14    108.005226  6798  ip-10-0-41-167  10.0.41.167   \n",
       "23  2023-08-30_21-20-18    112.345067  6798  ip-10-0-41-167  10.0.41.167   \n",
       "24  2023-08-30_21-20-23    116.679629  6798  ip-10-0-41-167  10.0.41.167   \n",
       "25  2023-08-30_21-20-27    121.027131  6798  ip-10-0-41-167  10.0.41.167   \n",
       "26  2023-08-30_21-20-31    125.404580  6798  ip-10-0-41-167  10.0.41.167   \n",
       "27  2023-08-30_21-20-36    129.780868  6798  ip-10-0-41-167  10.0.41.167   \n",
       "28  2023-08-30_21-20-40    134.138587  6798  ip-10-0-41-167  10.0.41.167   \n",
       "29  2023-08-30_21-20-45    138.479979  6798  ip-10-0-41-167  10.0.41.167   \n",
       "\n",
       "    time_since_restore  iterations_since_restore  \n",
       "0            12.171986                         1  \n",
       "1            16.506943                         2  \n",
       "2            20.826625                         3  \n",
       "3            25.199487                         4  \n",
       "4            29.527740                         5  \n",
       "5            33.894342                         6  \n",
       "6            38.253660                         7  \n",
       "7            42.604557                         8  \n",
       "8            46.952767                         9  \n",
       "9            51.293746                        10  \n",
       "10           55.672023                        11  \n",
       "11           60.038014                        12  \n",
       "12           64.396288                        13  \n",
       "13           68.776407                        14  \n",
       "14           73.162210                        15  \n",
       "15           77.512805                        16  \n",
       "16           81.867835                        17  \n",
       "17           86.197686                        18  \n",
       "18           90.530035                        19  \n",
       "19           94.853667                        20  \n",
       "20           99.269773                        21  \n",
       "21          103.619072                        22  \n",
       "22          108.005226                        23  \n",
       "23          112.345067                        24  \n",
       "24          116.679629                        25  \n",
       "25          121.027131                        26  \n",
       "26          125.404580                        27  \n",
       "27          129.780868                        28  \n",
       "28          134.138587                        29  \n",
       "29          138.479979                        30  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying RAG score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.query import QueryAgent\n",
    "\n",
    "records = data[\"results\"]\n",
    "\n",
    "agent = QueryAgent()\n",
    "\n",
    "for record in records:\n",
    "    embedding = np.array(agent.embedding_model.embed_query(record[\"question\"]))\n",
    "    with agent.conn.cursor() as cur:\n",
    "        cur.execute(\"SELECT * FROM document ORDER BY embedding <-> %s LIMIT 5\", (embedding,))\n",
    "        rows = cur.fetchall()\n",
    "    record[\"corr\"] = np.dot(rows[0][3], embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>generated_answer</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>score</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>sources</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>why it takes 10 mins for you to answer my ques...</td>\n",
       "      <td>Based on the provided context, it's likely tha...</td>\n",
       "      <td></td>\n",
       "      <td>2.00</td>\n",
       "      <td>The AI response seems well-explained with appr...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.832438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are you based on GPT-4?</td>\n",
       "      <td>Based on the provided context, it seems that G...</td>\n",
       "      <td></td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer does a good job addressin...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.848736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>if there are O(millions) of keys that all have...</td>\n",
       "      <td>It is generally not recommended to spin up 1 a...</td>\n",
       "      <td>In reference to the context provided, creating...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer accurately, clearly, and ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/examples/r...</td>\n",
       "      <td>0.849179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>What are the reasons for spikes in node CPU ut...</td>\n",
       "      <td>The reasons for spikes in node CPU utilization...</td>\n",
       "      <td>Spikes in node CPU utilization can be caused b...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer is quite informative and ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/faq.htm...</td>\n",
       "      <td>0.849213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Can I specify multiple working directories?</td>\n",
       "      <td>Yes, you can specify multiple working director...</td>\n",
       "      <td>No, you can only specify a single working dire...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect and does not...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/faq.html#h...</td>\n",
       "      <td>0.857076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>What is the working of `PowerOfTwoChoicesRepli...</td>\n",
       "      <td>The `PowerOfTwoChoicesReplicaScheduler` is a s...</td>\n",
       "      <td></td>\n",
       "      <td>4.80</td>\n",
       "      <td>The generated answer is well elaborated, with ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.863320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>How to update files in working directory ?</td>\n",
       "      <td>To update files in the working directory, you ...</td>\n",
       "      <td>To update files in the working directory, you ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is completely misleading ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/api/index...</td>\n",
       "      <td>0.863390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>What is the reason actors change their state t...</td>\n",
       "      <td>The reason actors change their state to unheal...</td>\n",
       "      <td>Actors change their state to 'unhealthy' or 'D...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>While the generated answer does attempt to ans...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/rl...</td>\n",
       "      <td>0.864036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>can’t pickle SSLContext objects</td>\n",
       "      <td>Based on the provided context, it seems that t...</td>\n",
       "      <td>SSLContext objects can't be pickled by default...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is very detailed and comp...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/object...</td>\n",
       "      <td>0.865827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>can you create a tweet thread from chapter 8, ...</td>\n",
       "      <td>Sure! Here's a possible tweet thread based on ...</td>\n",
       "      <td></td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is an accurately detailed...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.866004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>How do I make the GPU available on my M1 lapto...</td>\n",
       "      <td>To make the GPU available on your M1 laptop to...</td>\n",
       "      <td>To make your GPU available for Ray on your M1 ...</td>\n",
       "      <td>3.75</td>\n",
       "      <td>The generated answer contains useful informati...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/tasks/...</td>\n",
       "      <td>0.866851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Do you know how to resolve (gcs_server) gcs_he...</td>\n",
       "      <td>Based on the provided context, it seems that t...</td>\n",
       "      <td>The error 'Health check failed for node' in gc...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is thoroughly detailed an...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/vms/use...</td>\n",
       "      <td>0.871206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>What is the rest api for getting the head node...</td>\n",
       "      <td>Based on the provided context, the REST API fo...</td>\n",
       "      <td>The REST API for getting the head node id is n...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides a lot of informa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.872275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Does Ray support NCCL?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>Yes, Ray does support NCCL.</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer does correctly state that...</td>\n",
       "      <td>[https://docs.ray.io/en/master/train/faq.html#...</td>\n",
       "      <td>0.874034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>what size of memory should I need for this if ...</td>\n",
       "      <td>Based on the provided context, it seems that y...</td>\n",
       "      <td>To run the model 'EleutherAI/gpt-j-6B', at lea...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is quite comprehensive an...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/exampl...</td>\n",
       "      <td>0.874090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>What will be implicitly put into object store?</td>\n",
       "      <td>Based on the provided context, the following w...</td>\n",
       "      <td>In Ray, objects are implicitly put into object...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer provided a detailed expla...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/schedu...</td>\n",
       "      <td>0.874276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>What are the reasons for a node to change it’s...</td>\n",
       "      <td>Based on the provided context, a node may chan...</td>\n",
       "      <td>A node changes it's status to dead when there ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/ut...</td>\n",
       "      <td>0.874333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>can you give me the dependencies list for api ...</td>\n",
       "      <td>Sure! Based on the provided context, the depen...</td>\n",
       "      <td>The dependencies for the `read_images` API fro...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer is partially correct but ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.874789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>how do I do an all_reduce operation among a li...</td>\n",
       "      <td>To perform an all_reduce operation among a lis...</td>\n",
       "      <td>To perform an all_reduce operation among a lis...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer fails to accurately answe...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/rl...</td>\n",
       "      <td>0.877337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>One of my worker nodes keeps dying on using Te...</td>\n",
       "      <td>The error message you see suggests that the wo...</td>\n",
       "      <td>When your worker node is consistently failing ...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provides a thorough appro...</td>\n",
       "      <td>[https://docs.ray.io/en/master/train/examples/...</td>\n",
       "      <td>0.877630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>How do I set the max parallel concurrent sched...</td>\n",
       "      <td>To set the maximum number of parallel concurre...</td>\n",
       "      <td>In map_batches, to set the max parallel concur...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer gives a general explanati...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/tu...</td>\n",
       "      <td>0.878447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>what are the advantage and disadvantage of usi...</td>\n",
       "      <td>Advantages of using a singleton actor:\\n\\n* Ea...</td>\n",
       "      <td>The advantages of using singleton Actor are: 1...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer did a decent job at detai...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/patter...</td>\n",
       "      <td>0.878577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>how do I set custom /tmp directory for remote ...</td>\n",
       "      <td>To set a custom /tmp directory for a remote cl...</td>\n",
       "      <td>You can set a custom /tmp directory for the re...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provided a method to set ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/advanced-...</td>\n",
       "      <td>0.878739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>How I stop Ray from spamming lots of Info upda...</td>\n",
       "      <td>To stop Ray from spamming lots of info updates...</td>\n",
       "      <td>To stop Ray from spamming lots of Info updates...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer is partially accurate bec...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.879932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>what are the possible reasons for nodes dying ...</td>\n",
       "      <td>Based on the provided context, here are some p...</td>\n",
       "      <td>There are several possible reasons for nodes d...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a thorough expla...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/schedu...</td>\n",
       "      <td>0.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>What AWS machine type is recommended to deploy...</td>\n",
       "      <td>Based on the provided context, the recommended...</td>\n",
       "      <td>The recommended AWS machine type to deploy a R...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer does not specify the type...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.881185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>how can I quickly narrow down the root case of...</td>\n",
       "      <td>To quickly narrow down the root cause of a fai...</td>\n",
       "      <td>To quickly narrow down the root cause of a fai...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides comprehensive st...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.881507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>can you write a script to do batch inference w...</td>\n",
       "      <td>Sure, here's a possible script that demonstrat...</td>\n",
       "      <td>To perform inference with a pre-trained model ...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer created a script that can...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/working-wi...</td>\n",
       "      <td>0.882508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>how to utilize ‘zero-copy’ feature ray provide...</td>\n",
       "      <td>To utilize the 'zero-copy' feature provided by...</td>\n",
       "      <td>Ray optimizes for numpy arrays by using the Pi...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>While the generated answer provides an accurat...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.882523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>How the GCS determines which Kubernetes pod to...</td>\n",
       "      <td>The question is: How does GCS determine which ...</td>\n",
       "      <td>The Ray autoscaler on Kubernetes through KubeR...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer incorrectly states that G...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.883282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>how to pickle a variable defined in actor’s in...</td>\n",
       "      <td>It looks like you are trying to pickle an acto...</td>\n",
       "      <td>To pickle a variable defined in actor’s init m...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer correctly addresses the s...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/ac...</td>\n",
       "      <td>0.883559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>How do I access logs for a dead node?</td>\n",
       "      <td>Unfortunately, it is not possible to access lo...</td>\n",
       "      <td>Ray does not provide a native storage solution...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer not only explains why it ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.884642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>how can I avoid objects not getting spilled?</td>\n",
       "      <td>To avoid objects not getting spilled, you can ...</td>\n",
       "      <td>You can avoid objects from getting spilled in ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a detailed respo...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/object...</td>\n",
       "      <td>0.885939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>How do I set a maximum episode length when tra...</td>\n",
       "      <td>To set a maximum episode length when training ...</td>\n",
       "      <td>In RLlib, you can set a maximum episode length...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/rl...</td>\n",
       "      <td>0.886036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Does ray support cron job</td>\n",
       "      <td>Based on the provided context, the answer to t...</td>\n",
       "      <td>No, Ray does not directly support cron jobs. H...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>While the generated answer correctly states th...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.886235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How do I log the results from multiple distrib...</td>\n",
       "      <td>To log the results from multiple distributed w...</td>\n",
       "      <td>To log the results from multiple distributed w...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>While the generated answer gives a detailed wa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/tutorials/...</td>\n",
       "      <td>0.886383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ray serve returns generic internal service err...</td>\n",
       "      <td>To get more detailed errors or logs when Ray S...</td>\n",
       "      <td>To enable more detailed logging in Ray Serve, ...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>While the assistant does provide an answer tal...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/fault-...</td>\n",
       "      <td>0.887970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>how can I write unit tests for Ray code?</td>\n",
       "      <td>To write unit tests for Ray code, you can use ...</td>\n",
       "      <td>You can write unit tests for Ray code by using...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer correctly describes how t...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/da...</td>\n",
       "      <td>0.888114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>ray crashing with AttributeError: module 'pyda...</td>\n",
       "      <td>Based on the provided context, it seems that t...</td>\n",
       "      <td></td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a well-explained...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/se...</td>\n",
       "      <td>0.888190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>how do I kill a specific serve replica</td>\n",
       "      <td>Based on the provided context, you can kill a ...</td>\n",
       "      <td>To kill a specific Serve application replica, ...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer contains useful informati...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.888191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>How I can update working directory file when r...</td>\n",
       "      <td>To update the working directory file when Ray ...</td>\n",
       "      <td>To update a working directory file when Ray is...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer focuses heavily on changi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.888669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Why would I use Ray Serve instead of Modal or ...</td>\n",
       "      <td>Sure! Here's an answer to the query based on t...</td>\n",
       "      <td>Ray Serve provides several advantages for serv...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/index.htm...</td>\n",
       "      <td>0.889397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>How to resolve ValueError: The actor ImplicitF...</td>\n",
       "      <td>The error message \"ValueError: The actor Impli...</td>\n",
       "      <td>To resolve the ValueError: 'The actor Implicit...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is very comprehensive and...</td>\n",
       "      <td>[https://docs.ray.io/en/master/train/examples/...</td>\n",
       "      <td>0.889521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>How do I do global shuffle with Ray?</td>\n",
       "      <td>To do a global shuffle with Ray, you can use t...</td>\n",
       "      <td>You can perform a global shuffle with Ray by u...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provides a detailed and a...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/performanc...</td>\n",
       "      <td>0.890114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>my ray tuner shows \"running\" but CPU usage is ...</td>\n",
       "      <td>The reason why your Ray tuner shows \"running\" ...</td>\n",
       "      <td>The low CPU usage on your ray tuner may be cau...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>While the generated answer is comprehensive an...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/data-inter...</td>\n",
       "      <td>0.890151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>What’s the import path that I need to provide ...</td>\n",
       "      <td>Based on the code snippets you provided, it lo...</td>\n",
       "      <td>The import path you need to provide to a simpl...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides extensive inform...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/model_com...</td>\n",
       "      <td>0.890186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>how to add log inside actor?</td>\n",
       "      <td>To add a log inside an actor in Ray, you can u...</td>\n",
       "      <td>To add log inside actor in Ray, you will initi...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>The generated answer effectively answers the q...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.892411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>How to force upgrade the pip package in the ru...</td>\n",
       "      <td>To force upgrade the pip package in a runtime ...</td>\n",
       "      <td>To force upgrade the pip package in the runtim...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provided a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/ru...</td>\n",
       "      <td>0.892768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>How do I read a large text file in S3 with Ray?</td>\n",
       "      <td>To read a large text file in S3 with Ray, you ...</td>\n",
       "      <td>To read a large text file in S3 with Ray, you ...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer started off well, explain...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/examples/p...</td>\n",
       "      <td>0.893308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>how can I force ray head node to use custom pe...</td>\n",
       "      <td>To force the Ray head node to use a custom PEM...</td>\n",
       "      <td>auth:\\n    ssh_user: ubuntu\\n    ssh_private_k...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer is partially correct and ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.893326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>how do I use wandb logger with accelerateTrainer?</td>\n",
       "      <td>To use Wandb logger with AccelerateTrainer, yo...</td>\n",
       "      <td>It seems that you want to use the wandblogger ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is very inaccurate compar...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/examples/t...</td>\n",
       "      <td>0.893776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Is there a way to retrieve an object ref from ...</td>\n",
       "      <td>Yes, you can retrieve an object ref from its I...</td>\n",
       "      <td>No, there is no mention of a method or way to ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect. It mistaken...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.894088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>where does ray GCS store the history of jobs r...</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>Ray GCS stores the history of jobs run on a ku...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer contains information abou...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.894130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>what are the advantages of using a named actor?</td>\n",
       "      <td>Using named actors in Ray provides several adv...</td>\n",
       "      <td>Named actors in Ray programming provide severa...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is comprehensive, detaile...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/actors...</td>\n",
       "      <td>0.894431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How would you compare Spark, Ray, Dask?</td>\n",
       "      <td>Spark, Ray, and Dask are all powerful tools fo...</td>\n",
       "      <td>When it comes to batch services, Ray Data sepa...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/vms/use...</td>\n",
       "      <td>0.894967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What is the difference between PACK and SPREAD...</td>\n",
       "      <td>The difference between PACK and SPREAD strateg...</td>\n",
       "      <td>The PACK and SPREAD strategies are part of Ray...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer correctly explains the di...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/rl...</td>\n",
       "      <td>0.895421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>how to push a custom module to ray which is us...</td>\n",
       "      <td>To push a custom module to Ray that is using a...</td>\n",
       "      <td>To push a custom module to ray which is being ...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer provides extensive and de...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.895541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>when starting cluster with ray up, there are f...</td>\n",
       "      <td>It sounds like you are having issues with node...</td>\n",
       "      <td>If you're seeing nodes pending for a significa...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>While the generated answer provides a detailed...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.896089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Is there a way to configure the session name g...</td>\n",
       "      <td>Yes, you can configure the session name genera...</td>\n",
       "      <td>Each Ray session will indeed have a unique nam...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer suggests that you can cus...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/config...</td>\n",
       "      <td>0.896462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>How do I use ray to distribute training for my...</td>\n",
       "      <td>To use Ray to distribute training for your cus...</td>\n",
       "      <td>The given code is already a complete solution ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer does not match the refere...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/api/int...</td>\n",
       "      <td>0.896595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>If I shutdown a raylet, will the tasks and wor...</td>\n",
       "      <td>Based on the provided context, the answer to t...</td>\n",
       "      <td>Yes, if you shutdown a raylet, the tasks and w...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer does touch upon on the im...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/cl...</td>\n",
       "      <td>0.896873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>how to print ray working directory?</td>\n",
       "      <td>To print the working directory of Ray, you can...</td>\n",
       "      <td>Ray does not provide a direct method to print ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect as it provid...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-contribute/...</td>\n",
       "      <td>0.897870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>what might be the reason for  \"ray up\" not sta...</td>\n",
       "      <td>Based on the provided context, it's likely tha...</td>\n",
       "      <td>There could be multiple reasons 'ray up' is no...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>While the generated answer provides a more det...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.898791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>when you use ray dataset to read a file, can y...</td>\n",
       "      <td>Yes, you can preserve the order of the data wh...</td>\n",
       "      <td>Yes, you can ensure the order of the data is p...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is completely accurate. I...</td>\n",
       "      <td>[https://docs.ray.io/en/master/train/distribut...</td>\n",
       "      <td>0.898864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>What may possible cause the node where this ta...</td>\n",
       "      <td>Based on the provided context, there are sever...</td>\n",
       "      <td>The node where the task was running could have...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer is comprehensive and well...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/schedu...</td>\n",
       "      <td>0.899008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>where I can find HTTP server error code log fo...</td>\n",
       "      <td>Based on the provided context, it seems that y...</td>\n",
       "      <td>Ray Serve uses Python’s standard logging modul...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides useful informati...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/api/index...</td>\n",
       "      <td>0.899320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is Ray integrated with DeepSpeed?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>Yes, Ray is integrated with DeepSpeed.</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer does not provide a direct...</td>\n",
       "      <td>[https://docs.ray.io/en/master/train/examples/...</td>\n",
       "      <td>0.901059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>How to set memory limit for each trial in Ray ...</td>\n",
       "      <td>To set a memory limit for each trial in Ray Tu...</td>\n",
       "      <td>To set memory limit for each trial in Ray Tune...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer provides incorrect inform...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/data-inter...</td>\n",
       "      <td>0.901151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>How can I add a timeout for the Ray job?</td>\n",
       "      <td>You can add a timeout for the Ray job using th...</td>\n",
       "      <td>To add a timeout for a Ray Job, you can use th...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provided by the AI is tec...</td>\n",
       "      <td>[https://docs.ray.io/en/master/genindex.html, ...</td>\n",
       "      <td>0.902390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>How to use callback in Trainer?</td>\n",
       "      <td>It looks like you are trying to use the `Callb...</td>\n",
       "      <td>In order to use a callback in Trainer with Ray...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer contains relevant informa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/tr...</td>\n",
       "      <td>0.902621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>how do I specify in my remote function declara...</td>\n",
       "      <td>To specify that you want the task to run on a ...</td>\n",
       "      <td>In the declaration of your remote function, yo...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is inaccurate. Ray does n...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/tasks....</td>\n",
       "      <td>0.902658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>how do I join two ray datasets?</td>\n",
       "      <td>To join two Ray datasets, you can use the `ray...</td>\n",
       "      <td>To join two ray datasets, you will need to use...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect as it sugges...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.902717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>why I can not see log.info in ray log?</td>\n",
       "      <td>Based on the provided context, it seems that t...</td>\n",
       "      <td>Based on the context provided, you might not s...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer does not accurately respo...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/monitorin...</td>\n",
       "      <td>0.904220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>How to provide current working directory to ray?</td>\n",
       "      <td>To provide the current working directory to Ra...</td>\n",
       "      <td>To provide the current working directory to Ra...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect because it s...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.904309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can i create my own ray image with custom pyth...</td>\n",
       "      <td>Yes, you can create your own Ray image with a ...</td>\n",
       "      <td></td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is comprehensive and seem...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.904421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>how to install Ray 2.5.1 from github or wheel?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>To install Ray 2.5.1, you should use the pip i...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provides a detailed proce...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-contribute/...</td>\n",
       "      <td>0.904679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>If I specify a fractional GPU in the resource ...</td>\n",
       "      <td>If you specify a fractional GPU in the resourc...</td>\n",
       "      <td>If you specify a fractional GPU in the resourc...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is mostly correct, provid...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/examples/t...</td>\n",
       "      <td>0.904945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>why would ray overload a node w/ more task tha...</td>\n",
       "      <td>Ray would not overload a node with more tasks ...</td>\n",
       "      <td>Ray could overload a node with more tasks than...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>The generated answer is indeed quite insightfu...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/patter...</td>\n",
       "      <td>0.905105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>what doess the GCS server do, and why is my GC...</td>\n",
       "      <td>The GCS (Global Control Service) server is a c...</td>\n",
       "      <td>The GCS Server is not explicitly defined in th...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a thorough, rele...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.905106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>is there a way to load and run inference witho...</td>\n",
       "      <td>Yes, it is possible to run inference without u...</td>\n",
       "      <td>Yes, Ray Serve is a framework-agnostic scalabl...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer is incorrect and misleadi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/api/doc...</td>\n",
       "      <td>0.905477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Can you tell me more about the strict_mode in ...</td>\n",
       "      <td>Sure, I can help you with that!\\n\\nStrict mode...</td>\n",
       "      <td></td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provides a detailed overv...</td>\n",
       "      <td>[https://docs.ray.io/en/master/train/examples/...</td>\n",
       "      <td>0.905527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do I get the address of a ray node</td>\n",
       "      <td>Based on the provided context, it seems that y...</td>\n",
       "      <td>To get the address of a ray node, you can util...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer fails to mention the `ray...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/faq.htm...</td>\n",
       "      <td>0.905782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>On remote ray cluster, when I do `ray debug` I...</td>\n",
       "      <td>The error \"connection refused\" indicates that ...</td>\n",
       "      <td>The connection refused error might be occurrin...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer provides comprehensive tr...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.906784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>how do i track an uncaught exception in ray serve</td>\n",
       "      <td>To track an uncaught exception in Ray Serve, y...</td>\n",
       "      <td>Ray Serve uses the Python standard logging mod...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer provides detailed steps o...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.907334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Is the order of the input data preserved after...</td>\n",
       "      <td>No, the order of the input data is not preserv...</td>\n",
       "      <td>Yes, the order of the input data is preserved ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer contains all necessary in...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.907486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>How can I kill a \"detached\" Actor ?</td>\n",
       "      <td>You can kill a detached actor using the `ray.k...</td>\n",
       "      <td>You can kill a detached Actor by using the 'ra...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer includes all the informat...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/actors...</td>\n",
       "      <td>0.907727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>how to send  extra arguments in dataset.map_ba...</td>\n",
       "      <td>You can send extra arguments to the `map_batch...</td>\n",
       "      <td>To send extra arguments in the dataset.map_bat...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated response does provide informatio...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.907976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Does Ray metrics have to be exported via an ac...</td>\n",
       "      <td>No, Ray metrics do not have to be exported via...</td>\n",
       "      <td>No, Ray metrics do not have to be exported via...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer correctly states that Ray...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/metrics...</td>\n",
       "      <td>0.907976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>If I’d like to debug out of memory, how do I D...</td>\n",
       "      <td>To debug out-of-memory issues in Ray, you can ...</td>\n",
       "      <td>To debug out of memory, firstly, you need to i...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer does not correctly addres...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.908137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>how do I programatically get ray remote cluste...</td>\n",
       "      <td>To programmatically get a Ray remote cluster t...</td>\n",
       "      <td>Within a Ray program, you can command the auto...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provides a fairly detaile...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/tutorials/...</td>\n",
       "      <td>0.908340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>how to use Ray dataset on aws</td>\n",
       "      <td>To use a Ray dataset on AWS, you can follow th...</td>\n",
       "      <td>You can use the Ray dataset on AWS by implemen...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.909217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>how to find local ray address</td>\n",
       "      <td>To find the local Ray address, you can follow ...</td>\n",
       "      <td>To find local Ray address, import the ray modu...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer includes a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.909391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>How to take a subset of a Ray Dataset?</td>\n",
       "      <td>To take a subset of a Ray Dataset, you can use...</td>\n",
       "      <td>To take a subset of a Ray Dataset, you can use...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is excellent. It correctl...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.909835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>For the supervised actor pattern, can we keep ...</td>\n",
       "      <td>Yes, it is possible to keep the Worker Actor u...</td>\n",
       "      <td>No, we cannot keep the Worker Actor up if the ...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer incorrectly states that w...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/patter...</td>\n",
       "      <td>0.909935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>What should be the value of `maxConcurrentRepl...</td>\n",
       "      <td>The value of `maxConcurrentReplicas` should be...</td>\n",
       "      <td>The value of `maxConcurrentReplicas` is not pr...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer explains the setting of `...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/se...</td>\n",
       "      <td>0.910104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>How do I use `worker_setup_hook` in a runtime ...</td>\n",
       "      <td>To use `worker_setup_hook` in a runtime enviro...</td>\n",
       "      <td>In order to set up some configuration on worke...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides a lot of details...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.910245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>how to create an actor instance with parameter?</td>\n",
       "      <td>To create an actor instance with parameters us...</td>\n",
       "      <td>In Python, to create an actor instance with a ...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>The generated answer provides a detailed expla...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/exampl...</td>\n",
       "      <td>0.910982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>How to cancel job from UI?</td>\n",
       "      <td>To cancel a job from the UI, you can use the `...</td>\n",
       "      <td>To cancel a job from the UI using Ray, follow ...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer extensively discusses sev...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.911161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how can i go about fine tuning a LLM with Ray?</td>\n",
       "      <td>Sure, here's a possible response based on the ...</td>\n",
       "      <td></td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer is highly detailed and pr...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-overview/ex...</td>\n",
       "      <td>0.911308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Do you need the DAGDriver to deploy a serve ap...</td>\n",
       "      <td>Yes, you need the DAGDriver to deploy a serve ...</td>\n",
       "      <td>No, you do not need the DAGDriver to deploy a ...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is completely inaccurate....</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/advanced-...</td>\n",
       "      <td>0.911450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What is user config in Ray Serve? how do I use...</td>\n",
       "      <td>User config in Ray Serve refers to the configu...</td>\n",
       "      <td>User config in Ray Serve is a config passed to...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer seems to be confusing the...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.911494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>How do I do inference from a model trained by ...</td>\n",
       "      <td>To perform inference from a model trained by R...</td>\n",
       "      <td>After training a model with Ray Train, proceed...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer contains some inaccuracie...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>could you give me an example of using this lib...</td>\n",
       "      <td>Sure, here's an example of using the Ray libra...</td>\n",
       "      <td>For data-parallel training of CNNs on Ray, you...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer has incorrect information...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/api/int...</td>\n",
       "      <td>0.911632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>how to launch a ray cluster with 10 nodes, wit...</td>\n",
       "      <td>To launch a Ray cluster with 10 nodes without ...</td>\n",
       "      <td>To launch a ray cluster with 10 nodes, without...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer provides detailed steps o...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/ut...</td>\n",
       "      <td>0.912331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>How to disconnnect ray client?</td>\n",
       "      <td>Based on the provided context, here's an examp...</td>\n",
       "      <td>To disconnect the Ray client, you can call the...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is comprehensive, thoroug...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.912875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>show a map batch example with batch_format</td>\n",
       "      <td>Sure, here's an example of a map batch with ba...</td>\n",
       "      <td>Ray Data can handle batches in the form of dic...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The AI's answer does provide an example of a m...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.912890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How do I read a text file stored on S3 using R...</td>\n",
       "      <td>To read a text file stored on S3 using Ray Dat...</td>\n",
       "      <td>To read a text file stored on S3 using Ray Dat...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is accurate, detailed and...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/examples/h...</td>\n",
       "      <td>0.913080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>we plan to use Ray cloud launcher to start a c...</td>\n",
       "      <td>To specify a subnet in the deployment file whe...</td>\n",
       "      <td>To specify a subnet in the Ray deployment file...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides clear and concis...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/exampl...</td>\n",
       "      <td>0.913198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>How do I get started?</td>\n",
       "      <td>Sure, here's an answer to the query \"How do I ...</td>\n",
       "      <td>To get started with Ray, you need to determine...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is largely accurate and p...</td>\n",
       "      <td>[https://docs.ray.io/en/master/rllib/rllib-off...</td>\n",
       "      <td>0.913383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>I am running ray cluster on amazon and I have ...</td>\n",
       "      <td>It seems like you are experiencing issues with...</td>\n",
       "      <td>When using Ray on Amazon, the dashboard port m...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer effectively addresses the...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.913574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>is it possible to have ray on k8s without usin...</td>\n",
       "      <td>Yes, it is possible to have Ray on Kubernetes ...</td>\n",
       "      <td>Yes, it is possible to have Ray on Kubernetes ...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provides a thorough, deta...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.913743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>can I use the Python SDK to get a link to Ray ...</td>\n",
       "      <td>Yes, you can use the Python SDK to get a link ...</td>\n",
       "      <td>Yes, you can use the Python SDK to get a link ...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides detailed informa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.914214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>How do I debug a hanging `ray.get()` call? I h...</td>\n",
       "      <td>If you are experiencing a hanging `ray.get()` ...</td>\n",
       "      <td>To debug a hanging `ray.get()` call, you can u...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer does not align with the r...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/patter...</td>\n",
       "      <td>0.914230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>do you have any documents / examples showing t...</td>\n",
       "      <td>Here is an example of a RayJob CR (Custom Reso...</td>\n",
       "      <td>Yes, you can run a Ray job by creating a RayJo...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides useful informati...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.914386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>what does ray do</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>Ray is an open-source unified framework used f...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer is highly detailed and at...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.914415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>can you give me an example of using `ray.data....</td>\n",
       "      <td>Sure! Here's an example of using `ray.data.map...</td>\n",
       "      <td>Sure, here's an example code snippet that uses...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer is very comprehensive and...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.914495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>how to kill a r detached actors?</td>\n",
       "      <td>To kill a detached actor in Ray, you can use t...</td>\n",
       "      <td>Once you are certain that the detached actors ...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer is quite detailed and pro...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/actors...</td>\n",
       "      <td>0.914584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how to scatter actors across the cluster?</td>\n",
       "      <td>To scatter actors across the cluster, you can ...</td>\n",
       "      <td>To scatter actors across the cluster, you can ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>While the generated answer provides a detailed...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.915756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How does Ray AIR set up the model to communica...</td>\n",
       "      <td>Ray AIR sets up the model to communicate gradi...</td>\n",
       "      <td>The provided context does not provide specific...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides detailed informa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.916158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>where can I see logs for a failed ray serve de...</td>\n",
       "      <td>Sure! Here's a summary of the information prov...</td>\n",
       "      <td>You can see logs for a failed Ray Serve deploy...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides useful details o...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.916743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>How to get the best AIR checkpoint after train...</td>\n",
       "      <td>To get the best AIR checkpoint after training ...</td>\n",
       "      <td>To get the best AIR checkpoint after training ...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>While the generated answer does provide a vali...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/examples/t...</td>\n",
       "      <td>0.916792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>How to specify python version in runtime_env?</td>\n",
       "      <td>To specify the Python version in the `runtime_...</td>\n",
       "      <td>To specify Python version in runtime_env, you ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is quite detailed and cov...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.917161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>how to create a Actor in a namespace?</td>\n",
       "      <td>To create an actor in a namespace, you can use...</td>\n",
       "      <td>To create an actor in a namespace in Python: F...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provides a detailed expos...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/namesp...</td>\n",
       "      <td>0.917462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>how do I specify ScalingConfig for a Tuner run?</td>\n",
       "      <td>To specify a ScalingConfig for a Tuner run, yo...</td>\n",
       "      <td>To specify ScalingConfig for a Tuner run, incl...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer is technically sound and ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/tu...</td>\n",
       "      <td>0.917809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>How do I kill or cancel a ray task that I alre...</td>\n",
       "      <td>To cancel a Ray task that you have already sta...</td>\n",
       "      <td>To cancel a task in Ray that you've already st...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer correctly explains how to...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.917950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what will happen if I use AsyncIO's await to w...</td>\n",
       "      <td>Based on the provided context, it seems that u...</td>\n",
       "      <td>If you use AsyncIO's await to wait for a Ray f...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated response is incorrect and confus...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/actors...</td>\n",
       "      <td>0.918007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How do I deploy an LLM workload on top of Ray ...</td>\n",
       "      <td>To deploy an LLM workload on top of Ray Serve,...</td>\n",
       "      <td>To deploy an LLM workload using Ray Serve, sta...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer provides a lot of accurat...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/develop-a...</td>\n",
       "      <td>0.918046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>how to rerun a canceled ray task</td>\n",
       "      <td>Unfortunately, it's not possible to re-run a c...</td>\n",
       "      <td>To rerun a canceled ray task, you would need t...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is largely correct, provi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.918125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What’s the best way to run ray across multiple...</td>\n",
       "      <td>The best way to run Ray across multiple machin...</td>\n",
       "      <td>To run Ray across multiple machines, you must ...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is mostly aligned with th...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/faq.htm...</td>\n",
       "      <td>0.918205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>I want to kill the replica actor from Python. ...</td>\n",
       "      <td>You can use the `ray.kill()` function to kill ...</td>\n",
       "      <td>You can terminate the actor from Python utiliz...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer features a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.918840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>In the Ray cluster launcher YAML, does `max_wo...</td>\n",
       "      <td>Based on the provided context, the `max_worker...</td>\n",
       "      <td>The `max_workers` in the Ray cluster launcher ...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is in-depth, articulate a...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-overview/ge...</td>\n",
       "      <td>0.919166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>should the Ray head node and all workers have ...</td>\n",
       "      <td>Based on the provided context, it is not neces...</td>\n",
       "      <td>No, the Ray head node and worker nodes do not ...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is well written and expla...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.919186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>how do I debug why ray rollout workers are dea...</td>\n",
       "      <td>Based on the provided context, it seems that y...</td>\n",
       "      <td>To debug why ray rollout workers are deadlocki...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated response gives a clear and detai...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/rl...</td>\n",
       "      <td>0.919340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>In Ray Serve, how to specify whether to set up...</td>\n",
       "      <td>To specify whether to set up an HTTP proxy on ...</td>\n",
       "      <td>In Ray Serve, you can specify whether to set u...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.919560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>how to create model Checkpoint from the model ...</td>\n",
       "      <td>You can create a `TransformersCheckpoint` from...</td>\n",
       "      <td>To create a model checkpoint from the model in...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer's quality is below averag...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/tr...</td>\n",
       "      <td>0.919909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>What does the `compute=actor`  argument do wit...</td>\n",
       "      <td>The `compute=ray.data.ActorPoolStrategy()` arg...</td>\n",
       "      <td>The `compute` argument in `ray.data.map_batche...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer elaborates on the functio...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/examples/n...</td>\n",
       "      <td>0.920008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>how to submit job with python with local files?</td>\n",
       "      <td>To submit a job with Python using local files,...</td>\n",
       "      <td>You can submit a job with Python and local fil...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provided similar informat...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.920224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>How to setup the development environments for ...</td>\n",
       "      <td>Sure! Based on the provided context, here's a ...</td>\n",
       "      <td>To set up the development environments for the...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>While the generated answer provides several wa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-contribute/...</td>\n",
       "      <td>0.920602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>how to use ray api to scale up a cluster</td>\n",
       "      <td>To use the Ray API to scale up a cluster, you ...</td>\n",
       "      <td>To scale up a cluster using ray API, you use t...</td>\n",
       "      <td>4.75</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/overview.h...</td>\n",
       "      <td>0.920639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>How can I set the `request_timeout_s` in `http...</td>\n",
       "      <td>To set the `request_timeout_s` in the `http_op...</td>\n",
       "      <td>In the `http_options` section of a Ray Serve Y...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer perfectly and completely ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.921096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Why the function for Ray data batch inference ...</td>\n",
       "      <td>The function for Ray data batch inference has ...</td>\n",
       "      <td>The function for Ray data batch inference is n...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/tr...</td>\n",
       "      <td>0.921326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>How to use the exclude option to the runtime_env</td>\n",
       "      <td>To use the `exclude` option to the `runtime_en...</td>\n",
       "      <td>The 'exclude' option in the 'runtime_env' is u...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect. It misinter...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.921482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>how do I use Ray Data to pre process many files?</td>\n",
       "      <td>To use Ray Data for preprocessing many files, ...</td>\n",
       "      <td>To transform batches with tasks, call map_batc...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides a general overvi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.921666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>How to find namespace of an Actor?</td>\n",
       "      <td>Sure, here's an answer to the query based on t...</td>\n",
       "      <td>Using the Ray utility method ray.util.state.li...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>While the generated answer does provide a way ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/_p...</td>\n",
       "      <td>0.921710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>how do you config SyncConfig for a Ray AIR job?</td>\n",
       "      <td>To configure SyncConfig for a Ray AIR job, you...</td>\n",
       "      <td>To configure SyncConfig for a Ray AIR job, you...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer does not provide accurate...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/api/doc/ra...</td>\n",
       "      <td>0.921728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>if I set --temp-dir to a different directory t...</td>\n",
       "      <td>Based on the provided context, the answer to t...</td>\n",
       "      <td>Yes, if you set --temp-dir to a different dire...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer is generally accurate and...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.921751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>can you give me an example for *`--runtime-env...</td>\n",
       "      <td>Sure, here's an example of using the `--runtim...</td>\n",
       "      <td>You can specify a runtime environment for your...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect. The generat...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/api/doc/r...</td>\n",
       "      <td>0.923006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>What will happen if we specify a bundle with `...</td>\n",
       "      <td>If you specify a bundle with `{\"CPU\": 0}` in t...</td>\n",
       "      <td>If you specify a bundle with {'CPU':0} in the ...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer aligns with the reference...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/schedu...</td>\n",
       "      <td>0.923007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>How do I get the number of cpus from ray cluster?</td>\n",
       "      <td>To get the number of CPUs in a Ray cluster, yo...</td>\n",
       "      <td>You can get the number of CPUs from ray cluste...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is highly detailed, provi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.923084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>can you show me an example of ray.actor.exit_a...</td>\n",
       "      <td>Sure, here's an example of using `ray.actor.ex...</td>\n",
       "      <td>Indeed, you can manually terminate an actor fr...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer explains how to use `ray....</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/actors...</td>\n",
       "      <td>0.923596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>where do I view logs using python logger emitt...</td>\n",
       "      <td>To view logs emitted by your Ray Serve endpoin...</td>\n",
       "      <td>In Ray Serve, logs are emitted from actors bot...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer seems quite elaborate and...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.924051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>how do I get the actor id of an actor</td>\n",
       "      <td>To get the actor ID of an actor, you can use t...</td>\n",
       "      <td>To get the actor id of an actor in ray, you ca...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provided code examples an...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/ru...</td>\n",
       "      <td>0.924726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>what if I set num_cpus=0 for tasks</td>\n",
       "      <td>If you set `num_cpus=0` for tasks, it means th...</td>\n",
       "      <td>Setting num_cpus=0 for tasks in Ray means that...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provided a thorough expla...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/tips-f...</td>\n",
       "      <td>0.924990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>How do I specify how many GPUs a serve deploym...</td>\n",
       "      <td>To specify how many GPUs a serve deployment ne...</td>\n",
       "      <td>To assign hardware resources per replica, such...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Both the generated answer and the reference an...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/develop-a...</td>\n",
       "      <td>0.925041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>How do I enable Ray debug logs?</td>\n",
       "      <td>To enable Ray debug logs, you can follow these...</td>\n",
       "      <td>To enable Ray debug logs, you have to adjust t...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer does a very good job of e...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.925198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m struggling a bit with Ray Data type conver...</td>\n",
       "      <td>It appears that you are struggling with config...</td>\n",
       "      <td>When you're handling Ray Data type conversions...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated response accurately addresses th...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/da...</td>\n",
       "      <td>0.925697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>How does Ray work with async.io ?</td>\n",
       "      <td>Ray works with async.io by allowing the invoca...</td>\n",
       "      <td>Ray is designed to natively integrate with asy...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is detailed and captures ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/tips-f...</td>\n",
       "      <td>0.925720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>how do I get my project files on the cluster w...</td>\n",
       "      <td>To get your project files on the cluster when ...</td>\n",
       "      <td>To get your project files on the cluster when ...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer provides accurate informa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/productio...</td>\n",
       "      <td>0.926384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Can you explain what \"Ray will *not* retry tas...</td>\n",
       "      <td>Sure, I'd be happy to help!\\n\\nThe statement \"...</td>\n",
       "      <td>The statement \\\\</td>\n",
       "      <td>1.00</td>\n",
       "      <td>This answer seems to be completely off-topic f...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/tasks....</td>\n",
       "      <td>0.926734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Want to embed Grafana into the Ray Dashboard, ...</td>\n",
       "      <td>Given that you are using KubeRay and Prometheu...</td>\n",
       "      <td>The `RAY_GRAFANA_HOST` should be set to the IP...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The assistant provides a highly detailed answe...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/configu...</td>\n",
       "      <td>0.926969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>How do I list the current Ray actors from python?</td>\n",
       "      <td>To list the current Ray actors from Python, yo...</td>\n",
       "      <td>To list the current Ray actors from python, yo...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer provides a lot of informa...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.928757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>how to deploy stable diffusion 2.1 with Ray Se...</td>\n",
       "      <td>To deploy a stable diffusion 2.1 model with Ra...</td>\n",
       "      <td>To serve a Stable Diffusion application with R...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer has attempted to provide ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/tutorials...</td>\n",
       "      <td>0.928836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>How do I install CRDs in Kuberay?</td>\n",
       "      <td>Sure, here's an answer to the query based on t...</td>\n",
       "      <td>To install CRDs in Kuberay, you need to deploy...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provides accurate and det...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.928879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Yes what should be the value of `max_concurren...</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>The value of `max_concurrent_queries` should b...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer is extensive and tries to...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/scaling-a...</td>\n",
       "      <td>0.928892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>How do I set env variables in ray init? Let’ s...</td>\n",
       "      <td>To set environment variables in Ray, you can u...</td>\n",
       "      <td>To set environment variables when initializing...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is incredibly detailed, c...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.929030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>how do I get the IP of the head node for my Ra...</td>\n",
       "      <td>To get the IP address of the head node for you...</td>\n",
       "      <td>To get the IP of the head node for your Ray cl...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect and does not...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/cli.htm...</td>\n",
       "      <td>0.929098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>How to start ray cluster on multiple node via ...</td>\n",
       "      <td>To start a Ray cluster on multiple nodes via t...</td>\n",
       "      <td>You can start a Ray cluster on multiple nodes ...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer tries to explain the proc...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/vms/use...</td>\n",
       "      <td>0.929503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>what is the different between a batch and a bl...</td>\n",
       "      <td>In the context of Ray datasets, a batch and a ...</td>\n",
       "      <td>In Ray datasets, a Dataset is a sequence of Ra...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provided a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-references/...</td>\n",
       "      <td>0.930895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>What exactly is rayjob? How is it handled in k...</td>\n",
       "      <td>Sure, I can answer your query using the provid...</td>\n",
       "      <td></td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is detailed and comprehen...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.931484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>can ray.init() can check if ray is all-ready i...</td>\n",
       "      <td>Yes, `ray.init()` can check if Ray has already...</td>\n",
       "      <td>Yes, ray.init() if called again, it will ignor...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer mostly explains the conce...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/api/do...</td>\n",
       "      <td>0.932492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>how to use ray.put and ray,get?</td>\n",
       "      <td>Sure, here's an answer to the query using the ...</td>\n",
       "      <td>The ray.put() function is used to put a Python...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is well-explained and tho...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/exampl...</td>\n",
       "      <td>0.933479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>how do i install the latest ray nightly wheel?</td>\n",
       "      <td>To install the latest Ray nightly wheel, you c...</td>\n",
       "      <td>To install the latest nightly Ray wheel, first...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer misses the 'uninstall' st...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-overview/in...</td>\n",
       "      <td>0.933494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>how do i install ray nightly wheel</td>\n",
       "      <td>To install the nightly Ray wheels, you can use...</td>\n",
       "      <td>To install the nightly Ray wheels, you should ...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is exceptionally detailed...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-more-libs/i...</td>\n",
       "      <td>0.934124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>How do I avoid my dataset shuffling during a r...</td>\n",
       "      <td>To avoid dataset shuffling during a `ray.data....</td>\n",
       "      <td>To avoid shuffling your dataset during a ray.d...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer is correct, comprehensive...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.934144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>how to manually configure and manage Ray clust...</td>\n",
       "      <td>To manually configure and manage a Ray cluster...</td>\n",
       "      <td>To manually configure and manage a Ray cluster...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer provides a general overvi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/kuberne...</td>\n",
       "      <td>0.936190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>how do you disable async iter_batches with Ray...</td>\n",
       "      <td>To disable async iter_batches with Ray Dataset...</td>\n",
       "      <td>The ability to disable async iter_batches with...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer inaccurately implies that...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.936484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>How to write a map function that returns a lis...</td>\n",
       "      <td>To write a map function that returns a list of...</td>\n",
       "      <td>To compose a map function that returns a list ...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>The generated answer does provide a code examp...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-air/example...</td>\n",
       "      <td>0.938923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>how do I specify the log directory when starti...</td>\n",
       "      <td>To specify the log directory when starting Ray...</td>\n",
       "      <td>You can specify the log directory when startin...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>The generated answer is mostly accurate with t...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-observabili...</td>\n",
       "      <td>0.938978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>How to find the best checkpoint from the trial...</td>\n",
       "      <td>To find the best checkpoint from the trial dir...</td>\n",
       "      <td>You can use ExperimentAnalysis's method named ...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer provides a comprehensive ...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/tu...</td>\n",
       "      <td>0.939239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>what is actor_handle?</td>\n",
       "      <td>Based on the provided context, `actor_handle` ...</td>\n",
       "      <td>An Actor handle is a reference to the actor in...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides good information...</td>\n",
       "      <td>[https://docs.ray.io/en/master/_modules/ray/ac...</td>\n",
       "      <td>0.941243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>what is a `smoothing_factor`</td>\n",
       "      <td>Based on the provided context, `smoothing_fact...</td>\n",
       "      <td>The `smoothing_factor` in the context of autos...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer provides a generally corr...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/scaling-a...</td>\n",
       "      <td>0.942521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>how do I make a Ray Tune trial retry on failures?</td>\n",
       "      <td>To make a Ray Tune trial retry on failures, yo...</td>\n",
       "      <td>To enable a Ray Tune trial to retry on failure...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>The generated answer is incorrect and misleadi...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/tutorials/...</td>\n",
       "      <td>0.944248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>can you give me an example of using `ray.data....</td>\n",
       "      <td>Certainly! Here's an example of using `ray.dat...</td>\n",
       "      <td>You use `ray.data.Dataset.map` in Python by pa...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>The generated answer provides a useful and top...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.944631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>How do I load all checkpoints from trials of a...</td>\n",
       "      <td>To load all checkpoints from trials of a Tune ...</td>\n",
       "      <td>To access all the checkpoints from trials of a...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>The generated answer is not completely correct...</td>\n",
       "      <td>[https://docs.ray.io/en/master/tune/tutorials/...</td>\n",
       "      <td>0.947279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does autoscaling work in a Ray Serve appli...</td>\n",
       "      <td>Autoscaling in a Ray Serve application works b...</td>\n",
       "      <td>Autoscaling in Ray Serve works with the help o...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer accurately presents the c...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/scaling-a...</td>\n",
       "      <td>0.949477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>how do I get a ray dataset from pandas</td>\n",
       "      <td>To create a Ray Dataset from a pandas DataFram...</td>\n",
       "      <td>You can convert a Pandas DataFrame into a Ray ...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer perfectly answers the giv...</td>\n",
       "      <td>[https://docs.ray.io/en/master/data/api/doc/ra...</td>\n",
       "      <td>0.951803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>when should I use Ray Client?</td>\n",
       "      <td>Based on the provided context, Ray Client shou...</td>\n",
       "      <td>Ray Client should be used when you want to con...</td>\n",
       "      <td>4.50</td>\n",
       "      <td>The generated answer is quite detailed, coveri...</td>\n",
       "      <td>[https://docs.ray.io/en/master/cluster/running...</td>\n",
       "      <td>0.959641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>what is Deployment in Ray Serve?</td>\n",
       "      <td>Based on the provided context, it appears that...</td>\n",
       "      <td>In Ray Serve, a deployment contains business l...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>The generated answer provides a quality defini...</td>\n",
       "      <td>[https://docs.ray.io/en/master/serve/api/doc/r...</td>\n",
       "      <td>0.967734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>what’s ray core</td>\n",
       "      <td>Based on the provided context, Ray Core is an ...</td>\n",
       "      <td>Ray Core is a system that provides a few core ...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>The generated answer accurately describes what...</td>\n",
       "      <td>[https://docs.ray.io/en/master/ray-core/walkth...</td>\n",
       "      <td>0.989103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "5    why it takes 10 mins for you to answer my ques...   \n",
       "4                              are you based on GPT-4?   \n",
       "42   if there are O(millions) of keys that all have...   \n",
       "172  What are the reasons for spikes in node CPU ut...   \n",
       "107        Can I specify multiple working directories?   \n",
       "178  What is the working of `PowerOfTwoChoicesRepli...   \n",
       "128         How to update files in working directory ?   \n",
       "169  What is the reason actors change their state t...   \n",
       "71                     can’t pickle SSLContext objects   \n",
       "15   can you create a tweet thread from chapter 8, ...   \n",
       "161  How do I make the GPU available on my M1 lapto...   \n",
       "177  Do you know how to resolve (gcs_server) gcs_he...   \n",
       "146  What is the rest api for getting the head node...   \n",
       "6                               Does Ray support NCCL?   \n",
       "20   what size of memory should I need for this if ...   \n",
       "63      What will be implicitly put into object store?   \n",
       "171  What are the reasons for a node to change it’s...   \n",
       "186  can you give me the dependencies list for api ...   \n",
       "81   how do I do an all_reduce operation among a li...   \n",
       "25   One of my worker nodes keeps dying on using Te...   \n",
       "148  How do I set the max parallel concurrent sched...   \n",
       "45   what are the advantage and disadvantage of usi...   \n",
       "163  how do I set custom /tmp directory for remote ...   \n",
       "88   How I stop Ray from spamming lots of Info upda...   \n",
       "26   what are the possible reasons for nodes dying ...   \n",
       "173  What AWS machine type is recommended to deploy...   \n",
       "23   how can I quickly narrow down the root case of...   \n",
       "99   can you write a script to do batch inference w...   \n",
       "41   how to utilize ‘zero-copy’ feature ray provide...   \n",
       "159  How the GCS determines which Kubernetes pod to...   \n",
       "80   how to pickle a variable defined in actor’s in...   \n",
       "170              How do I access logs for a dead node?   \n",
       "183       how can I avoid objects not getting spilled?   \n",
       "51   How do I set a maximum episode length when tra...   \n",
       "185                          Does ray support cron job   \n",
       "21   How do I log the results from multiple distrib...   \n",
       "138  ray serve returns generic internal service err...   \n",
       "87            how can I write unit tests for Ray code?   \n",
       "153  ray crashing with AttributeError: module 'pyda...   \n",
       "187             how do I kill a specific serve replica   \n",
       "129  How I can update working directory file when r...   \n",
       "18   Why would I use Ray Serve instead of Modal or ...   \n",
       "67   How to resolve ValueError: The actor ImplicitF...   \n",
       "93                How do I do global shuffle with Ray?   \n",
       "155  my ray tuner shows \"running\" but CPU usage is ...   \n",
       "180  What’s the import path that I need to provide ...   \n",
       "98                        how to add log inside actor?   \n",
       "92   How to force upgrade the pip package in the ru...   \n",
       "54     How do I read a large text file in S3 with Ray?   \n",
       "130  how can I force ray head node to use custom pe...   \n",
       "62   how do I use wandb logger with accelerateTrainer?   \n",
       "34   Is there a way to retrieve an object ref from ...   \n",
       "66   where does ray GCS store the history of jobs r...   \n",
       "46     what are the advantages of using a named actor?   \n",
       "10             How would you compare Spark, Ray, Dask?   \n",
       "38   What is the difference between PACK and SPREAD...   \n",
       "116  how to push a custom module to ray which is us...   \n",
       "132  when starting cluster with ray up, there are f...   \n",
       "174  Is there a way to configure the session name g...   \n",
       "68   How do I use ray to distribute training for my...   \n",
       "111  If I shutdown a raylet, will the tasks and wor...   \n",
       "117                how to print ray working directory?   \n",
       "30   what might be the reason for  \"ray up\" not sta...   \n",
       "119  when you use ray dataset to read a file, can y...   \n",
       "176  What may possible cause the node where this ta...   \n",
       "125  where I can find HTTP server error code log fo...   \n",
       "8                    Is Ray integrated with DeepSpeed?   \n",
       "58   How to set memory limit for each trial in Ray ...   \n",
       "162           How can I add a timeout for the Ray job?   \n",
       "113                    How to use callback in Trainer?   \n",
       "103  how do I specify in my remote function declara...   \n",
       "33                     how do I join two ray datasets?   \n",
       "118             why I can not see log.info in ray log?   \n",
       "114   How to provide current working directory to ray?   \n",
       "2    can i create my own ray image with custom pyth...   \n",
       "133     how to install Ray 2.5.1 from github or wheel?   \n",
       "79   If I specify a fractional GPU in the resource ...   \n",
       "11   why would ray overload a node w/ more task tha...   \n",
       "131  what doess the GCS server do, and why is my GC...   \n",
       "77   is there a way to load and run inference witho...   \n",
       "50   Can you tell me more about the strict_mode in ...   \n",
       "3               how do I get the address of a ray node   \n",
       "16   On remote ray cluster, when I do `ray debug` I...   \n",
       "139  how do i track an uncaught exception in ray serve   \n",
       "137  Is the order of the input data preserved after...   \n",
       "144                How can I kill a \"detached\" Actor ?   \n",
       "65   how to send  extra arguments in dataset.map_ba...   \n",
       "182  Does Ray metrics have to be exported via an ac...   \n",
       "112  If I’d like to debug out of memory, how do I D...   \n",
       "27   how do I programatically get ray remote cluste...   \n",
       "135                      how to use Ray dataset on aws   \n",
       "152                      how to find local ray address   \n",
       "142             How to take a subset of a Ray Dataset?   \n",
       "53   For the supervised actor pattern, can we keep ...   \n",
       "166  What should be the value of `maxConcurrentRepl...   \n",
       "134  How do I use `worker_setup_hook` in a runtime ...   \n",
       "115    how to create an actor instance with parameter?   \n",
       "83                          How to cancel job from UI?   \n",
       "14      how can i go about fine tuning a LLM with Ray?   \n",
       "179  Do you need the DAGDriver to deploy a serve ap...   \n",
       "37   What is user config in Ray Serve? how do I use...   \n",
       "76   How do I do inference from a model trained by ...   \n",
       "7    could you give me an example of using this lib...   \n",
       "122  how to launch a ray cluster with 10 nodes, wit...   \n",
       "74                      How to disconnnect ray client?   \n",
       "151         show a map batch example with batch_format   \n",
       "47   How do I read a text file stored on S3 using R...   \n",
       "124  we plan to use Ray cloud launcher to start a c...   \n",
       "104                              How do I get started?   \n",
       "126  I am running ray cluster on amazon and I have ...   \n",
       "109  is it possible to have ray on k8s without usin...   \n",
       "175  can I use the Python SDK to get a link to Ray ...   \n",
       "96   How do I debug a hanging `ray.get()` call? I h...   \n",
       "181  do you have any documents / examples showing t...   \n",
       "78                                    what does ray do   \n",
       "57   can you give me an example of using `ray.data....   \n",
       "91                    how to kill a r detached actors?   \n",
       "13           how to scatter actors across the cluster?   \n",
       "17   How does Ray AIR set up the model to communica...   \n",
       "141  where can I see logs for a failed ray serve de...   \n",
       "43   How to get the best AIR checkpoint after train...   \n",
       "105      How to specify python version in runtime_env?   \n",
       "106              how to create a Actor in a namespace?   \n",
       "40     how do I specify ScalingConfig for a Tuner run?   \n",
       "64   How do I kill or cancel a ray task that I alre...   \n",
       "9    what will happen if I use AsyncIO's await to w...   \n",
       "19   How do I deploy an LLM workload on top of Ray ...   \n",
       "147                   how to rerun a canceled ray task   \n",
       "39   What’s the best way to run ray across multiple...   \n",
       "102  I want to kill the replica actor from Python. ...   \n",
       "127  In the Ray cluster launcher YAML, does `max_wo...   \n",
       "156  should the Ray head node and all workers have ...   \n",
       "32   how do I debug why ray rollout workers are dea...   \n",
       "157  In Ray Serve, how to specify whether to set up...   \n",
       "35   how to create model Checkpoint from the model ...   \n",
       "61   What does the `compute=actor`  argument do wit...   \n",
       "75     how to submit job with python with local files?   \n",
       "31   How to setup the development environments for ...   \n",
       "123           how to use ray api to scale up a cluster   \n",
       "160  How can I set the `request_timeout_s` in `http...   \n",
       "73   Why the function for Ray data batch inference ...   \n",
       "150   How to use the exclude option to the runtime_env   \n",
       "70    how do I use Ray Data to pre process many files?   \n",
       "94                  How to find namespace of an Actor?   \n",
       "22     how do you config SyncConfig for a Ray AIR job?   \n",
       "164  if I set --temp-dir to a different directory t...   \n",
       "165  can you give me an example for *`--runtime-env...   \n",
       "82   What will happen if we specify a bundle with `...   \n",
       "149  How do I get the number of cpus from ray cluster?   \n",
       "97   can you show me an example of ray.actor.exit_a...   \n",
       "140  where do I view logs using python logger emitt...   \n",
       "59               how do I get the actor id of an actor   \n",
       "108                 what if I set num_cpus=0 for tasks   \n",
       "24   How do I specify how many GPUs a serve deploym...   \n",
       "100                    How do I enable Ray debug logs?   \n",
       "0    I’m struggling a bit with Ray Data type conver...   \n",
       "95                   How does Ray work with async.io ?   \n",
       "84   how do I get my project files on the cluster w...   \n",
       "120  Can you explain what \"Ray will *not* retry tas...   \n",
       "158  Want to embed Grafana into the Ray Dashboard, ...   \n",
       "101  How do I list the current Ray actors from python?   \n",
       "89   how to deploy stable diffusion 2.1 with Ray Se...   \n",
       "72                   How do I install CRDs in Kuberay?   \n",
       "167  Yes what should be the value of `max_concurren...   \n",
       "145  How do I set env variables in ray init? Let’ s...   \n",
       "48   how do I get the IP of the head node for my Ra...   \n",
       "154  How to start ray cluster on multiple node via ...   \n",
       "29   what is the different between a batch and a bl...   \n",
       "188  What exactly is rayjob? How is it handled in k...   \n",
       "60   can ray.init() can check if ray is all-ready i...   \n",
       "69                     how to use ray.put and ray,get?   \n",
       "86      how do i install the latest ray nightly wheel?   \n",
       "85                  how do i install ray nightly wheel   \n",
       "136  How do I avoid my dataset shuffling during a r...   \n",
       "110  how to manually configure and manage Ray clust...   \n",
       "28   how do you disable async iter_batches with Ray...   \n",
       "49   How to write a map function that returns a lis...   \n",
       "121  how do I specify the log directory when starti...   \n",
       "44   How to find the best checkpoint from the trial...   \n",
       "90                               what is actor_handle?   \n",
       "168                       what is a `smoothing_factor`   \n",
       "52   how do I make a Ray Tune trial retry on failures?   \n",
       "56   can you give me an example of using `ray.data....   \n",
       "143  How do I load all checkpoints from trials of a...   \n",
       "1    How does autoscaling work in a Ray Serve appli...   \n",
       "55              how do I get a ray dataset from pandas   \n",
       "12                       when should I use Ray Client?   \n",
       "36                    what is Deployment in Ray Serve?   \n",
       "184                                    what’s ray core   \n",
       "\n",
       "                                      generated_answer  \\\n",
       "5    Based on the provided context, it's likely tha...   \n",
       "4    Based on the provided context, it seems that G...   \n",
       "42   It is generally not recommended to spin up 1 a...   \n",
       "172  The reasons for spikes in node CPU utilization...   \n",
       "107  Yes, you can specify multiple working director...   \n",
       "178  The `PowerOfTwoChoicesReplicaScheduler` is a s...   \n",
       "128  To update files in the working directory, you ...   \n",
       "169  The reason actors change their state to unheal...   \n",
       "71   Based on the provided context, it seems that t...   \n",
       "15   Sure! Here's a possible tweet thread based on ...   \n",
       "161  To make the GPU available on your M1 laptop to...   \n",
       "177  Based on the provided context, it seems that t...   \n",
       "146  Based on the provided context, the REST API fo...   \n",
       "6    Based on the provided context, it appears that...   \n",
       "20   Based on the provided context, it seems that y...   \n",
       "63   Based on the provided context, the following w...   \n",
       "171  Based on the provided context, a node may chan...   \n",
       "186  Sure! Based on the provided context, the depen...   \n",
       "81   To perform an all_reduce operation among a lis...   \n",
       "25   The error message you see suggests that the wo...   \n",
       "148  To set the maximum number of parallel concurre...   \n",
       "45   Advantages of using a singleton actor:\\n\\n* Ea...   \n",
       "163  To set a custom /tmp directory for a remote cl...   \n",
       "88   To stop Ray from spamming lots of info updates...   \n",
       "26   Based on the provided context, here are some p...   \n",
       "173  Based on the provided context, the recommended...   \n",
       "23   To quickly narrow down the root cause of a fai...   \n",
       "99   Sure, here's a possible script that demonstrat...   \n",
       "41   To utilize the 'zero-copy' feature provided by...   \n",
       "159  The question is: How does GCS determine which ...   \n",
       "80   It looks like you are trying to pickle an acto...   \n",
       "170  Unfortunately, it is not possible to access lo...   \n",
       "183  To avoid objects not getting spilled, you can ...   \n",
       "51   To set a maximum episode length when training ...   \n",
       "185  Based on the provided context, the answer to t...   \n",
       "21   To log the results from multiple distributed w...   \n",
       "138  To get more detailed errors or logs when Ray S...   \n",
       "87   To write unit tests for Ray code, you can use ...   \n",
       "153  Based on the provided context, it seems that t...   \n",
       "187  Based on the provided context, you can kill a ...   \n",
       "129  To update the working directory file when Ray ...   \n",
       "18   Sure! Here's an answer to the query based on t...   \n",
       "67   The error message \"ValueError: The actor Impli...   \n",
       "93   To do a global shuffle with Ray, you can use t...   \n",
       "155  The reason why your Ray tuner shows \"running\" ...   \n",
       "180  Based on the code snippets you provided, it lo...   \n",
       "98   To add a log inside an actor in Ray, you can u...   \n",
       "92   To force upgrade the pip package in a runtime ...   \n",
       "54   To read a large text file in S3 with Ray, you ...   \n",
       "130  To force the Ray head node to use a custom PEM...   \n",
       "62   To use Wandb logger with AccelerateTrainer, yo...   \n",
       "34   Yes, you can retrieve an object ref from its I...   \n",
       "66   Based on the provided context, it appears that...   \n",
       "46   Using named actors in Ray provides several adv...   \n",
       "10   Spark, Ray, and Dask are all powerful tools fo...   \n",
       "38   The difference between PACK and SPREAD strateg...   \n",
       "116  To push a custom module to Ray that is using a...   \n",
       "132  It sounds like you are having issues with node...   \n",
       "174  Yes, you can configure the session name genera...   \n",
       "68   To use Ray to distribute training for your cus...   \n",
       "111  Based on the provided context, the answer to t...   \n",
       "117  To print the working directory of Ray, you can...   \n",
       "30   Based on the provided context, it's likely tha...   \n",
       "119  Yes, you can preserve the order of the data wh...   \n",
       "176  Based on the provided context, there are sever...   \n",
       "125  Based on the provided context, it seems that y...   \n",
       "8    Based on the provided context, it appears that...   \n",
       "58   To set a memory limit for each trial in Ray Tu...   \n",
       "162  You can add a timeout for the Ray job using th...   \n",
       "113  It looks like you are trying to use the `Callb...   \n",
       "103  To specify that you want the task to run on a ...   \n",
       "33   To join two Ray datasets, you can use the `ray...   \n",
       "118  Based on the provided context, it seems that t...   \n",
       "114  To provide the current working directory to Ra...   \n",
       "2    Yes, you can create your own Ray image with a ...   \n",
       "133  Based on the provided context, it appears that...   \n",
       "79   If you specify a fractional GPU in the resourc...   \n",
       "11   Ray would not overload a node with more tasks ...   \n",
       "131  The GCS (Global Control Service) server is a c...   \n",
       "77   Yes, it is possible to run inference without u...   \n",
       "50   Sure, I can help you with that!\\n\\nStrict mode...   \n",
       "3    Based on the provided context, it seems that y...   \n",
       "16   The error \"connection refused\" indicates that ...   \n",
       "139  To track an uncaught exception in Ray Serve, y...   \n",
       "137  No, the order of the input data is not preserv...   \n",
       "144  You can kill a detached actor using the `ray.k...   \n",
       "65   You can send extra arguments to the `map_batch...   \n",
       "182  No, Ray metrics do not have to be exported via...   \n",
       "112  To debug out-of-memory issues in Ray, you can ...   \n",
       "27   To programmatically get a Ray remote cluster t...   \n",
       "135  To use a Ray dataset on AWS, you can follow th...   \n",
       "152  To find the local Ray address, you can follow ...   \n",
       "142  To take a subset of a Ray Dataset, you can use...   \n",
       "53   Yes, it is possible to keep the Worker Actor u...   \n",
       "166  The value of `maxConcurrentReplicas` should be...   \n",
       "134  To use `worker_setup_hook` in a runtime enviro...   \n",
       "115  To create an actor instance with parameters us...   \n",
       "83   To cancel a job from the UI, you can use the `...   \n",
       "14   Sure, here's a possible response based on the ...   \n",
       "179  Yes, you need the DAGDriver to deploy a serve ...   \n",
       "37   User config in Ray Serve refers to the configu...   \n",
       "76   To perform inference from a model trained by R...   \n",
       "7    Sure, here's an example of using the Ray libra...   \n",
       "122  To launch a Ray cluster with 10 nodes without ...   \n",
       "74   Based on the provided context, here's an examp...   \n",
       "151  Sure, here's an example of a map batch with ba...   \n",
       "47   To read a text file stored on S3 using Ray Dat...   \n",
       "124  To specify a subnet in the deployment file whe...   \n",
       "104  Sure, here's an answer to the query \"How do I ...   \n",
       "126  It seems like you are experiencing issues with...   \n",
       "109  Yes, it is possible to have Ray on Kubernetes ...   \n",
       "175  Yes, you can use the Python SDK to get a link ...   \n",
       "96   If you are experiencing a hanging `ray.get()` ...   \n",
       "181  Here is an example of a RayJob CR (Custom Reso...   \n",
       "78   Based on the provided context, it appears that...   \n",
       "57   Sure! Here's an example of using `ray.data.map...   \n",
       "91   To kill a detached actor in Ray, you can use t...   \n",
       "13   To scatter actors across the cluster, you can ...   \n",
       "17   Ray AIR sets up the model to communicate gradi...   \n",
       "141  Sure! Here's a summary of the information prov...   \n",
       "43   To get the best AIR checkpoint after training ...   \n",
       "105  To specify the Python version in the `runtime_...   \n",
       "106  To create an actor in a namespace, you can use...   \n",
       "40   To specify a ScalingConfig for a Tuner run, yo...   \n",
       "64   To cancel a Ray task that you have already sta...   \n",
       "9    Based on the provided context, it seems that u...   \n",
       "19   To deploy an LLM workload on top of Ray Serve,...   \n",
       "147  Unfortunately, it's not possible to re-run a c...   \n",
       "39   The best way to run Ray across multiple machin...   \n",
       "102  You can use the `ray.kill()` function to kill ...   \n",
       "127  Based on the provided context, the `max_worker...   \n",
       "156  Based on the provided context, it is not neces...   \n",
       "32   Based on the provided context, it seems that y...   \n",
       "157  To specify whether to set up an HTTP proxy on ...   \n",
       "35   You can create a `TransformersCheckpoint` from...   \n",
       "61   The `compute=ray.data.ActorPoolStrategy()` arg...   \n",
       "75   To submit a job with Python using local files,...   \n",
       "31   Sure! Based on the provided context, here's a ...   \n",
       "123  To use the Ray API to scale up a cluster, you ...   \n",
       "160  To set the `request_timeout_s` in the `http_op...   \n",
       "73   The function for Ray data batch inference has ...   \n",
       "150  To use the `exclude` option to the `runtime_en...   \n",
       "70   To use Ray Data for preprocessing many files, ...   \n",
       "94   Sure, here's an answer to the query based on t...   \n",
       "22   To configure SyncConfig for a Ray AIR job, you...   \n",
       "164  Based on the provided context, the answer to t...   \n",
       "165  Sure, here's an example of using the `--runtim...   \n",
       "82   If you specify a bundle with `{\"CPU\": 0}` in t...   \n",
       "149  To get the number of CPUs in a Ray cluster, yo...   \n",
       "97   Sure, here's an example of using `ray.actor.ex...   \n",
       "140  To view logs emitted by your Ray Serve endpoin...   \n",
       "59   To get the actor ID of an actor, you can use t...   \n",
       "108  If you set `num_cpus=0` for tasks, it means th...   \n",
       "24   To specify how many GPUs a serve deployment ne...   \n",
       "100  To enable Ray debug logs, you can follow these...   \n",
       "0    It appears that you are struggling with config...   \n",
       "95   Ray works with async.io by allowing the invoca...   \n",
       "84   To get your project files on the cluster when ...   \n",
       "120  Sure, I'd be happy to help!\\n\\nThe statement \"...   \n",
       "158  Given that you are using KubeRay and Prometheu...   \n",
       "101  To list the current Ray actors from Python, yo...   \n",
       "89   To deploy a stable diffusion 2.1 model with Ra...   \n",
       "72   Sure, here's an answer to the query based on t...   \n",
       "167  Based on the provided context, it appears that...   \n",
       "145  To set environment variables in Ray, you can u...   \n",
       "48   To get the IP address of the head node for you...   \n",
       "154  To start a Ray cluster on multiple nodes via t...   \n",
       "29   In the context of Ray datasets, a batch and a ...   \n",
       "188  Sure, I can answer your query using the provid...   \n",
       "60   Yes, `ray.init()` can check if Ray has already...   \n",
       "69   Sure, here's an answer to the query using the ...   \n",
       "86   To install the latest Ray nightly wheel, you c...   \n",
       "85   To install the nightly Ray wheels, you can use...   \n",
       "136  To avoid dataset shuffling during a `ray.data....   \n",
       "110  To manually configure and manage a Ray cluster...   \n",
       "28   To disable async iter_batches with Ray Dataset...   \n",
       "49   To write a map function that returns a list of...   \n",
       "121  To specify the log directory when starting Ray...   \n",
       "44   To find the best checkpoint from the trial dir...   \n",
       "90   Based on the provided context, `actor_handle` ...   \n",
       "168  Based on the provided context, `smoothing_fact...   \n",
       "52   To make a Ray Tune trial retry on failures, yo...   \n",
       "56   Certainly! Here's an example of using `ray.dat...   \n",
       "143  To load all checkpoints from trials of a Tune ...   \n",
       "1    Autoscaling in a Ray Serve application works b...   \n",
       "55   To create a Ray Dataset from a pandas DataFram...   \n",
       "12   Based on the provided context, Ray Client shou...   \n",
       "36   Based on the provided context, it appears that...   \n",
       "184  Based on the provided context, Ray Core is an ...   \n",
       "\n",
       "                                      reference_answer  score  \\\n",
       "5                                                        2.00   \n",
       "4                                                        4.00   \n",
       "42   In reference to the context provided, creating...   5.00   \n",
       "172  Spikes in node CPU utilization can be caused b...   4.50   \n",
       "107  No, you can only specify a single working dire...   1.00   \n",
       "178                                                      4.80   \n",
       "128  To update files in the working directory, you ...   1.00   \n",
       "169  Actors change their state to 'unhealthy' or 'D...   3.75   \n",
       "71   SSLContext objects can't be pickled by default...   4.00   \n",
       "15                                                       4.00   \n",
       "161  To make your GPU available for Ray on your M1 ...   3.75   \n",
       "177  The error 'Health check failed for node' in gc...   5.00   \n",
       "146  The REST API for getting the head node id is n...   2.00   \n",
       "6                          Yes, Ray does support NCCL.   3.50   \n",
       "20   To run the model 'EleutherAI/gpt-j-6B', at lea...   5.00   \n",
       "63   In Ray, objects are implicitly put into object...   3.00   \n",
       "171  A node changes it's status to dead when there ...   4.00   \n",
       "186  The dependencies for the `read_images` API fro...   2.50   \n",
       "81   To perform an all_reduce operation among a lis...   2.50   \n",
       "25   When your worker node is consistently failing ...   4.50   \n",
       "148  In map_batches, to set the max parallel concur...   2.00   \n",
       "45   The advantages of using singleton Actor are: 1...   4.00   \n",
       "163  You can set a custom /tmp directory for the re...   2.00   \n",
       "88   To stop Ray from spamming lots of Info updates...   3.50   \n",
       "26   There are several possible reasons for nodes d...   4.00   \n",
       "173  The recommended AWS machine type to deploy a R...   1.00   \n",
       "23   To quickly narrow down the root cause of a fai...   4.00   \n",
       "99   To perform inference with a pre-trained model ...   2.50   \n",
       "41   Ray optimizes for numpy arrays by using the Pi...   4.00   \n",
       "159  The Ray autoscaler on Kubernetes through KubeR...   2.00   \n",
       "80   To pickle a variable defined in actor’s init m...   2.00   \n",
       "170  Ray does not provide a native storage solution...   4.00   \n",
       "183  You can avoid objects from getting spilled in ...   4.00   \n",
       "51   In RLlib, you can set a maximum episode length...   3.50   \n",
       "185  No, Ray does not directly support cron jobs. H...   3.50   \n",
       "21   To log the results from multiple distributed w...   2.50   \n",
       "138  To enable more detailed logging in Ray Serve, ...   3.50   \n",
       "87   You can write unit tests for Ray code by using...   4.50   \n",
       "153                                                      4.00   \n",
       "187  To kill a specific Serve application replica, ...   2.00   \n",
       "129  To update a working directory file when Ray is...   2.50   \n",
       "18   Ray Serve provides several advantages for serv...   5.00   \n",
       "67   To resolve the ValueError: 'The actor Implicit...   4.00   \n",
       "93   You can perform a global shuffle with Ray by u...   3.50   \n",
       "155  The low CPU usage on your ray tuner may be cau...   3.50   \n",
       "180  The import path you need to provide to a simpl...   2.00   \n",
       "98   To add log inside actor in Ray, you will initi...   4.20   \n",
       "92   To force upgrade the pip package in the runtim...   4.50   \n",
       "54   To read a large text file in S3 with Ray, you ...   3.00   \n",
       "130  auth:\\n    ssh_user: ubuntu\\n    ssh_private_k...   2.50   \n",
       "62   It seems that you want to use the wandblogger ...   1.00   \n",
       "34   No, there is no mention of a method or way to ...   1.00   \n",
       "66   Ray GCS stores the history of jobs run on a ku...   2.00   \n",
       "46   Named actors in Ray programming provide severa...   5.00   \n",
       "10   When it comes to batch services, Ray Data sepa...   3.00   \n",
       "38   The PACK and SPREAD strategies are part of Ray...   5.00   \n",
       "116  To push a custom module to ray which is being ...   2.50   \n",
       "132  If you're seeing nodes pending for a significa...   4.00   \n",
       "174  Each Ray session will indeed have a unique nam...   2.50   \n",
       "68   The given code is already a complete solution ...   1.00   \n",
       "111  Yes, if you shutdown a raylet, the tasks and w...   4.00   \n",
       "117  Ray does not provide a direct method to print ...   1.00   \n",
       "30   There could be multiple reasons 'ray up' is no...   4.00   \n",
       "119  Yes, you can ensure the order of the data is p...   5.00   \n",
       "176  The node where the task was running could have...   4.50   \n",
       "125  Ray Serve uses Python’s standard logging modul...   4.00   \n",
       "8               Yes, Ray is integrated with DeepSpeed.   2.00   \n",
       "58   To set memory limit for each trial in Ray Tune...   1.00   \n",
       "162  To add a timeout for a Ray Job, you can use th...   2.00   \n",
       "113  In order to use a callback in Trainer with Ray...   2.00   \n",
       "103  In the declaration of your remote function, yo...   1.00   \n",
       "33   To join two ray datasets, you will need to use...   1.00   \n",
       "118  Based on the context provided, you might not s...   1.00   \n",
       "114  To provide the current working directory to Ra...   1.00   \n",
       "2                                                        1.00   \n",
       "133  To install Ray 2.5.1, you should use the pip i...   4.50   \n",
       "79   If you specify a fractional GPU in the resourc...   4.00   \n",
       "11   Ray could overload a node with more tasks than...   4.80   \n",
       "131  The GCS Server is not explicitly defined in th...   4.00   \n",
       "77   Yes, Ray Serve is a framework-agnostic scalabl...   2.00   \n",
       "50                                                       3.50   \n",
       "3    To get the address of a ray node, you can util...   3.00   \n",
       "16   The connection refused error might be occurrin...   3.00   \n",
       "139  Ray Serve uses the Python standard logging mod...   2.50   \n",
       "137  Yes, the order of the input data is preserved ...   4.00   \n",
       "144  You can kill a detached Actor by using the 'ra...   5.00   \n",
       "65   To send extra arguments in the dataset.map_bat...   3.50   \n",
       "182  No, Ray metrics do not have to be exported via...   4.00   \n",
       "112  To debug out of memory, firstly, you need to i...   1.00   \n",
       "27   Within a Ray program, you can command the auto...   4.50   \n",
       "135  You can use the Ray dataset on AWS by implemen...   4.00   \n",
       "152  To find local Ray address, import the ray modu...   4.50   \n",
       "142  To take a subset of a Ray Dataset, you can use...   5.00   \n",
       "53   No, we cannot keep the Worker Actor up if the ...   2.00   \n",
       "166  The value of `maxConcurrentReplicas` is not pr...   3.50   \n",
       "134  In order to set up some configuration on worke...   2.00   \n",
       "115  In Python, to create an actor instance with a ...   3.25   \n",
       "83   To cancel a job from the UI using Ray, follow ...   2.50   \n",
       "14                                                       3.00   \n",
       "179  No, you do not need the DAGDriver to deploy a ...   1.00   \n",
       "37   User config in Ray Serve is a config passed to...   1.00   \n",
       "76   After training a model with Ray Train, proceed...   3.50   \n",
       "7    For data-parallel training of CNNs on Ray, you...   1.00   \n",
       "122  To launch a ray cluster with 10 nodes, without...   2.50   \n",
       "74   To disconnect the Ray client, you can call the...   5.00   \n",
       "151  Ray Data can handle batches in the form of dic...   2.00   \n",
       "47   To read a text file stored on S3 using Ray Dat...   5.00   \n",
       "124  To specify a subnet in the Ray deployment file...   4.00   \n",
       "104  To get started with Ray, you need to determine...   4.00   \n",
       "126  When using Ray on Amazon, the dashboard port m...   5.00   \n",
       "109  Yes, it is possible to have Ray on Kubernetes ...   4.50   \n",
       "175  Yes, you can use the Python SDK to get a link ...   2.00   \n",
       "96   To debug a hanging `ray.get()` call, you can u...   1.00   \n",
       "181  Yes, you can run a Ray job by creating a RayJo...   4.00   \n",
       "78   Ray is an open-source unified framework used f...   2.50   \n",
       "57   Sure, here's an example code snippet that uses...   4.50   \n",
       "91   Once you are certain that the detached actors ...   4.50   \n",
       "13   To scatter actors across the cluster, you can ...   4.00   \n",
       "17   The provided context does not provide specific...   2.00   \n",
       "141  You can see logs for a failed Ray Serve deploy...   2.00   \n",
       "43   To get the best AIR checkpoint after training ...   2.50   \n",
       "105  To specify Python version in runtime_env, you ...   4.00   \n",
       "106  To create an actor in a namespace in Python: F...   3.50   \n",
       "40   To specify ScalingConfig for a Tuner run, incl...   3.50   \n",
       "64   To cancel a task in Ray that you've already st...   5.00   \n",
       "9    If you use AsyncIO's await to wait for a Ray f...   2.00   \n",
       "19   To deploy an LLM workload using Ray Serve, sta...   2.50   \n",
       "147  To rerun a canceled ray task, you would need t...   4.00   \n",
       "39   To run Ray across multiple machines, you must ...   4.00   \n",
       "102  You can terminate the actor from Python utiliz...   4.50   \n",
       "127  The `max_workers` in the Ray cluster launcher ...   5.00   \n",
       "156  No, the Ray head node and worker nodes do not ...   5.00   \n",
       "32   To debug why ray rollout workers are deadlocki...   4.00   \n",
       "157  In Ray Serve, you can specify whether to set u...   2.50   \n",
       "35   To create a model checkpoint from the model in...   2.00   \n",
       "61   The `compute` argument in `ray.data.map_batche...   5.00   \n",
       "75   You can submit a job with Python and local fil...   4.00   \n",
       "31   To set up the development environments for the...   3.00   \n",
       "123  To scale up a cluster using ray API, you use t...   4.75   \n",
       "160  In the `http_options` section of a Ray Serve Y...   5.00   \n",
       "73   The function for Ray data batch inference is n...   4.00   \n",
       "150  The 'exclude' option in the 'runtime_env' is u...   1.00   \n",
       "70   To transform batches with tasks, call map_batc...   2.00   \n",
       "94   Using the Ray utility method ray.util.state.li...   2.00   \n",
       "22   To configure SyncConfig for a Ray AIR job, you...   2.00   \n",
       "164  Yes, if you set --temp-dir to a different dire...   4.00   \n",
       "165  You can specify a runtime environment for your...   1.00   \n",
       "82   If you specify a bundle with {'CPU':0} in the ...   4.50   \n",
       "149  You can get the number of CPUs from ray cluste...   5.00   \n",
       "97   Indeed, you can manually terminate an actor fr...   4.00   \n",
       "140  In Ray Serve, logs are emitted from actors bot...   3.00   \n",
       "59   To get the actor id of an actor in ray, you ca...   3.50   \n",
       "108  Setting num_cpus=0 for tasks in Ray means that...   3.50   \n",
       "24   To assign hardware resources per replica, such...   5.00   \n",
       "100  To enable Ray debug logs, you have to adjust t...   5.00   \n",
       "0    When you're handling Ray Data type conversions...   4.00   \n",
       "95   Ray is designed to natively integrate with asy...   5.00   \n",
       "84   To get your project files on the cluster when ...   3.00   \n",
       "120                                   The statement \\\\   1.00   \n",
       "158  The `RAY_GRAFANA_HOST` should be set to the IP...   4.00   \n",
       "101  To list the current Ray actors from python, yo...   2.00   \n",
       "89   To serve a Stable Diffusion application with R...   2.50   \n",
       "72   To install CRDs in Kuberay, you need to deploy...   4.50   \n",
       "167  The value of `max_concurrent_queries` should b...   3.50   \n",
       "145  To set environment variables when initializing...   5.00   \n",
       "48   To get the IP of the head node for your Ray cl...   1.00   \n",
       "154  You can start a Ray cluster on multiple nodes ...   2.00   \n",
       "29   In Ray datasets, a Dataset is a sequence of Ra...   4.00   \n",
       "188                                                      5.00   \n",
       "60   Yes, ray.init() if called again, it will ignor...   3.50   \n",
       "69   The ray.put() function is used to put a Python...   5.00   \n",
       "86   To install the latest nightly Ray wheel, first...   2.00   \n",
       "85   To install the nightly Ray wheels, you should ...   5.00   \n",
       "136  To avoid shuffling your dataset during a ray.d...   5.00   \n",
       "110  To manually configure and manage a Ray cluster...   3.00   \n",
       "28   The ability to disable async iter_batches with...   2.00   \n",
       "49   To compose a map function that returns a list ...   2.50   \n",
       "121  You can specify the log directory when startin...   2.00   \n",
       "44   You can use ExperimentAnalysis's method named ...   4.50   \n",
       "90   An Actor handle is a reference to the actor in...   4.00   \n",
       "168  The `smoothing_factor` in the context of autos...   3.50   \n",
       "52   To enable a Ray Tune trial to retry on failure...   1.00   \n",
       "56   You use `ray.data.Dataset.map` in Python by pa...   3.00   \n",
       "143  To access all the checkpoints from trials of a...   3.50   \n",
       "1    Autoscaling in Ray Serve works with the help o...   5.00   \n",
       "55   You can convert a Pandas DataFrame into a Ray ...   5.00   \n",
       "12   Ray Client should be used when you want to con...   4.50   \n",
       "36   In Ray Serve, a deployment contains business l...   4.00   \n",
       "184  Ray Core is a system that provides a few core ...   5.00   \n",
       "\n",
       "                                             reasoning  \\\n",
       "5    The AI response seems well-explained with appr...   \n",
       "4    The generated answer does a good job addressin...   \n",
       "42   The generated answer accurately, clearly, and ...   \n",
       "172  The generated answer is quite informative and ...   \n",
       "107  The generated answer is incorrect and does not...   \n",
       "178  The generated answer is well elaborated, with ...   \n",
       "128  The generated answer is completely misleading ...   \n",
       "169  While the generated answer does attempt to ans...   \n",
       "71   The generated answer is very detailed and comp...   \n",
       "15   The generated answer is an accurately detailed...   \n",
       "161  The generated answer contains useful informati...   \n",
       "177  The generated answer is thoroughly detailed an...   \n",
       "146  The generated answer provides a lot of informa...   \n",
       "6    The generated answer does correctly state that...   \n",
       "20   The generated answer is quite comprehensive an...   \n",
       "63   The generated answer provided a detailed expla...   \n",
       "171  The generated answer provides a comprehensive ...   \n",
       "186  The generated answer is partially correct but ...   \n",
       "81   The generated answer fails to accurately answe...   \n",
       "25   The generated answer provides a thorough appro...   \n",
       "148  The generated answer gives a general explanati...   \n",
       "45   The generated answer did a decent job at detai...   \n",
       "163  The generated answer provided a method to set ...   \n",
       "88   The generated answer is partially accurate bec...   \n",
       "26   The generated answer provides a thorough expla...   \n",
       "173  The generated answer does not specify the type...   \n",
       "23   The generated answer provides comprehensive st...   \n",
       "99   The generated answer created a script that can...   \n",
       "41   While the generated answer provides an accurat...   \n",
       "159  The generated answer incorrectly states that G...   \n",
       "80   The generated answer correctly addresses the s...   \n",
       "170  The generated answer not only explains why it ...   \n",
       "183  The generated answer provides a detailed respo...   \n",
       "51   The generated answer provides a comprehensive ...   \n",
       "185  While the generated answer correctly states th...   \n",
       "21   While the generated answer gives a detailed wa...   \n",
       "138  While the assistant does provide an answer tal...   \n",
       "87   The generated answer correctly describes how t...   \n",
       "153  The generated answer provides a well-explained...   \n",
       "187  The generated answer contains useful informati...   \n",
       "129  The generated answer focuses heavily on changi...   \n",
       "18   The generated answer provides a comprehensive ...   \n",
       "67   The generated answer is very comprehensive and...   \n",
       "93   The generated answer provides a detailed and a...   \n",
       "155  While the generated answer is comprehensive an...   \n",
       "180  The generated answer provides extensive inform...   \n",
       "98   The generated answer effectively answers the q...   \n",
       "92   The generated answer provided a comprehensive ...   \n",
       "54   The generated answer started off well, explain...   \n",
       "130  The generated answer is partially correct and ...   \n",
       "62   The generated answer is very inaccurate compar...   \n",
       "34   The generated answer is incorrect. It mistaken...   \n",
       "66   The generated answer contains information abou...   \n",
       "46   The generated answer is comprehensive, detaile...   \n",
       "10   The generated answer provides a comprehensive ...   \n",
       "38   The generated answer correctly explains the di...   \n",
       "116  The generated answer provides extensive and de...   \n",
       "132  While the generated answer provides a detailed...   \n",
       "174  The generated answer suggests that you can cus...   \n",
       "68   The generated answer does not match the refere...   \n",
       "111  The generated answer does touch upon on the im...   \n",
       "117  The generated answer is incorrect as it provid...   \n",
       "30   While the generated answer provides a more det...   \n",
       "119  The generated answer is completely accurate. I...   \n",
       "176  The generated answer is comprehensive and well...   \n",
       "125  The generated answer provides useful informati...   \n",
       "8    The generated answer does not provide a direct...   \n",
       "58   The generated answer provides incorrect inform...   \n",
       "162  The generated answer provided by the AI is tec...   \n",
       "113  The generated answer contains relevant informa...   \n",
       "103  The generated answer is inaccurate. Ray does n...   \n",
       "33   The generated answer is incorrect as it sugges...   \n",
       "118  The generated answer does not accurately respo...   \n",
       "114  The generated answer is incorrect because it s...   \n",
       "2    The generated answer is comprehensive and seem...   \n",
       "133  The generated answer provides a detailed proce...   \n",
       "79   The generated answer is mostly correct, provid...   \n",
       "11   The generated answer is indeed quite insightfu...   \n",
       "131  The generated answer provides a thorough, rele...   \n",
       "77   The generated answer is incorrect and misleadi...   \n",
       "50   The generated answer provides a detailed overv...   \n",
       "3    The generated answer fails to mention the `ray...   \n",
       "16   The generated answer provides comprehensive tr...   \n",
       "139  The generated answer provides detailed steps o...   \n",
       "137  The generated answer contains all necessary in...   \n",
       "144  The generated answer includes all the informat...   \n",
       "65   The generated response does provide informatio...   \n",
       "182  The generated answer correctly states that Ray...   \n",
       "112  The generated answer does not correctly addres...   \n",
       "27   The generated answer provides a fairly detaile...   \n",
       "135  The generated answer provides a comprehensive ...   \n",
       "152  The generated answer includes a comprehensive ...   \n",
       "142  The generated answer is excellent. It correctl...   \n",
       "53   The generated answer incorrectly states that w...   \n",
       "166  The generated answer explains the setting of `...   \n",
       "134  The generated answer provides a lot of details...   \n",
       "115  The generated answer provides a detailed expla...   \n",
       "83   The generated answer extensively discusses sev...   \n",
       "14   The generated answer is highly detailed and pr...   \n",
       "179  The generated answer is completely inaccurate....   \n",
       "37   The generated answer seems to be confusing the...   \n",
       "76   The generated answer contains some inaccuracie...   \n",
       "7    The generated answer has incorrect information...   \n",
       "122  The generated answer provides detailed steps o...   \n",
       "74   The generated answer is comprehensive, thoroug...   \n",
       "151  The AI's answer does provide an example of a m...   \n",
       "47   The generated answer is accurate, detailed and...   \n",
       "124  The generated answer provides clear and concis...   \n",
       "104  The generated answer is largely accurate and p...   \n",
       "126  The generated answer effectively addresses the...   \n",
       "109  The generated answer provides a thorough, deta...   \n",
       "175  The generated answer provides detailed informa...   \n",
       "96   The generated answer does not align with the r...   \n",
       "181  The generated answer provides useful informati...   \n",
       "78   The generated answer is highly detailed and at...   \n",
       "57   The generated answer is very comprehensive and...   \n",
       "91   The generated answer is quite detailed and pro...   \n",
       "13   While the generated answer provides a detailed...   \n",
       "17   The generated answer provides detailed informa...   \n",
       "141  The generated answer provides useful details o...   \n",
       "43   While the generated answer does provide a vali...   \n",
       "105  The generated answer is quite detailed and cov...   \n",
       "106  The generated answer provides a detailed expos...   \n",
       "40   The generated answer is technically sound and ...   \n",
       "64   The generated answer correctly explains how to...   \n",
       "9    The generated response is incorrect and confus...   \n",
       "19   The generated answer provides a lot of accurat...   \n",
       "147  The generated answer is largely correct, provi...   \n",
       "39   The generated answer is mostly aligned with th...   \n",
       "102  The generated answer features a comprehensive ...   \n",
       "127  The generated answer is in-depth, articulate a...   \n",
       "156  The generated answer is well written and expla...   \n",
       "32   The generated response gives a clear and detai...   \n",
       "157  The generated answer provides a comprehensive ...   \n",
       "35   The generated answer's quality is below averag...   \n",
       "61   The generated answer elaborates on the functio...   \n",
       "75   The generated answer provided similar informat...   \n",
       "31   While the generated answer provides several wa...   \n",
       "123  The generated answer provides a comprehensive ...   \n",
       "160  The generated answer perfectly and completely ...   \n",
       "73   The generated answer provides a comprehensive ...   \n",
       "150  The generated answer is incorrect. It misinter...   \n",
       "70   The generated answer provides a general overvi...   \n",
       "94   While the generated answer does provide a way ...   \n",
       "22   The generated answer does not provide accurate...   \n",
       "164  The generated answer is generally accurate and...   \n",
       "165  The generated answer is incorrect. The generat...   \n",
       "82   The generated answer aligns with the reference...   \n",
       "149  The generated answer is highly detailed, provi...   \n",
       "97   The generated answer explains how to use `ray....   \n",
       "140  The generated answer seems quite elaborate and...   \n",
       "59   The generated answer provided code examples an...   \n",
       "108  The generated answer provided a thorough expla...   \n",
       "24   Both the generated answer and the reference an...   \n",
       "100  The generated answer does a very good job of e...   \n",
       "0    The generated response accurately addresses th...   \n",
       "95   The generated answer is detailed and captures ...   \n",
       "84   The generated answer provides accurate informa...   \n",
       "120  This answer seems to be completely off-topic f...   \n",
       "158  The assistant provides a highly detailed answe...   \n",
       "101  The generated answer provides a lot of informa...   \n",
       "89   The generated answer has attempted to provide ...   \n",
       "72   The generated answer provides accurate and det...   \n",
       "167  The generated answer is extensive and tries to...   \n",
       "145  The generated answer is incredibly detailed, c...   \n",
       "48   The generated answer is incorrect and does not...   \n",
       "154  The generated answer tries to explain the proc...   \n",
       "29   The generated answer provided a comprehensive ...   \n",
       "188  The generated answer is detailed and comprehen...   \n",
       "60   The generated answer mostly explains the conce...   \n",
       "69   The generated answer is well-explained and tho...   \n",
       "86   The generated answer misses the 'uninstall' st...   \n",
       "85   The generated answer is exceptionally detailed...   \n",
       "136  The generated answer is correct, comprehensive...   \n",
       "110  The generated answer provides a general overvi...   \n",
       "28   The generated answer inaccurately implies that...   \n",
       "49   The generated answer does provide a code examp...   \n",
       "121  The generated answer is mostly accurate with t...   \n",
       "44   The generated answer provides a comprehensive ...   \n",
       "90   The generated answer provides good information...   \n",
       "168  The generated answer provides a generally corr...   \n",
       "52   The generated answer is incorrect and misleadi...   \n",
       "56   The generated answer provides a useful and top...   \n",
       "143  The generated answer is not completely correct...   \n",
       "1    The generated answer accurately presents the c...   \n",
       "55   The generated answer perfectly answers the giv...   \n",
       "12   The generated answer is quite detailed, coveri...   \n",
       "36   The generated answer provides a quality defini...   \n",
       "184  The generated answer accurately describes what...   \n",
       "\n",
       "                                               sources      corr  \n",
       "5    [https://docs.ray.io/en/master/ray-core/api/do...  0.832438  \n",
       "4    [https://docs.ray.io/en/master/ray-air/example...  0.848736  \n",
       "42   [https://docs.ray.io/en/master/data/examples/r...  0.849179  \n",
       "172  [https://docs.ray.io/en/master/cluster/faq.htm...  0.849213  \n",
       "107  [https://docs.ray.io/en/master/tune/faq.html#h...  0.857076  \n",
       "178  [https://docs.ray.io/en/master/_modules/ray/_p...  0.863320  \n",
       "128  [https://docs.ray.io/en/master/serve/api/index...  0.863390  \n",
       "169  [https://docs.ray.io/en/master/_modules/ray/rl...  0.864036  \n",
       "71   [https://docs.ray.io/en/master/ray-core/object...  0.865827  \n",
       "15   [https://docs.ray.io/en/master/ray-air/example...  0.866004  \n",
       "161  [https://docs.ray.io/en/master/ray-core/tasks/...  0.866851  \n",
       "177  [https://docs.ray.io/en/master/cluster/vms/use...  0.871206  \n",
       "146  [https://docs.ray.io/en/master/ray-observabili...  0.872275  \n",
       "6    [https://docs.ray.io/en/master/train/faq.html#...  0.874034  \n",
       "20   [https://docs.ray.io/en/master/ray-core/exampl...  0.874090  \n",
       "63   [https://docs.ray.io/en/master/ray-core/schedu...  0.874276  \n",
       "171  [https://docs.ray.io/en/master/_modules/ray/ut...  0.874333  \n",
       "186  [https://docs.ray.io/en/master/serve/productio...  0.874789  \n",
       "81   [https://docs.ray.io/en/master/_modules/ray/rl...  0.877337  \n",
       "25   [https://docs.ray.io/en/master/train/examples/...  0.877630  \n",
       "148  [https://docs.ray.io/en/master/_modules/ray/tu...  0.878447  \n",
       "45   [https://docs.ray.io/en/master/ray-core/patter...  0.878577  \n",
       "163  [https://docs.ray.io/en/master/serve/advanced-...  0.878739  \n",
       "88   [https://docs.ray.io/en/master/ray-observabili...  0.879932  \n",
       "26   [https://docs.ray.io/en/master/ray-core/schedu...  0.881000  \n",
       "173  [https://docs.ray.io/en/master/serve/productio...  0.881185  \n",
       "23   [https://docs.ray.io/en/master/cluster/kuberne...  0.881507  \n",
       "99   [https://docs.ray.io/en/master/data/working-wi...  0.882508  \n",
       "41   [https://docs.ray.io/en/master/data/api/doc/ra...  0.882523  \n",
       "159  [https://docs.ray.io/en/master/cluster/kuberne...  0.883282  \n",
       "80   [https://docs.ray.io/en/master/_modules/ray/ac...  0.883559  \n",
       "170  [https://docs.ray.io/en/master/ray-observabili...  0.884642  \n",
       "183  [https://docs.ray.io/en/master/ray-core/object...  0.885939  \n",
       "51   [https://docs.ray.io/en/master/_modules/ray/rl...  0.886036  \n",
       "185  [https://docs.ray.io/en/master/ray-observabili...  0.886235  \n",
       "21   [https://docs.ray.io/en/master/tune/tutorials/...  0.886383  \n",
       "138  [https://docs.ray.io/en/master/ray-core/fault-...  0.887970  \n",
       "87   [https://docs.ray.io/en/master/_modules/ray/da...  0.888114  \n",
       "153  [https://docs.ray.io/en/master/_modules/ray/se...  0.888190  \n",
       "187  [https://docs.ray.io/en/master/serve/productio...  0.888191  \n",
       "129  [https://docs.ray.io/en/master/cluster/running...  0.888669  \n",
       "18   [https://docs.ray.io/en/master/serve/index.htm...  0.889397  \n",
       "67   [https://docs.ray.io/en/master/train/examples/...  0.889521  \n",
       "93   [https://docs.ray.io/en/master/data/performanc...  0.890114  \n",
       "155  [https://docs.ray.io/en/master/data/data-inter...  0.890151  \n",
       "180  [https://docs.ray.io/en/master/serve/model_com...  0.890186  \n",
       "98   [https://docs.ray.io/en/master/ray-observabili...  0.892411  \n",
       "92   [https://docs.ray.io/en/master/_modules/ray/ru...  0.892768  \n",
       "54   [https://docs.ray.io/en/master/data/examples/p...  0.893308  \n",
       "130  [https://docs.ray.io/en/master/cluster/running...  0.893326  \n",
       "62   [https://docs.ray.io/en/master/tune/examples/t...  0.893776  \n",
       "34   [https://docs.ray.io/en/master/_modules/ray/_p...  0.894088  \n",
       "66   [https://docs.ray.io/en/master/cluster/kuberne...  0.894130  \n",
       "46   [https://docs.ray.io/en/master/ray-core/actors...  0.894431  \n",
       "10   [https://docs.ray.io/en/master/cluster/vms/use...  0.894967  \n",
       "38   [https://docs.ray.io/en/master/_modules/ray/rl...  0.895421  \n",
       "116  [https://docs.ray.io/en/master/serve/productio...  0.895541  \n",
       "132  [https://docs.ray.io/en/master/serve/productio...  0.896089  \n",
       "174  [https://docs.ray.io/en/master/ray-core/config...  0.896462  \n",
       "68   [https://docs.ray.io/en/master/ray-air/api/int...  0.896595  \n",
       "111  [https://docs.ray.io/en/master/_modules/ray/cl...  0.896873  \n",
       "117  [https://docs.ray.io/en/master/ray-contribute/...  0.897870  \n",
       "30   [https://docs.ray.io/en/master/cluster/running...  0.898791  \n",
       "119  [https://docs.ray.io/en/master/train/distribut...  0.898864  \n",
       "176  [https://docs.ray.io/en/master/ray-core/schedu...  0.899008  \n",
       "125  [https://docs.ray.io/en/master/serve/api/index...  0.899320  \n",
       "8    [https://docs.ray.io/en/master/train/examples/...  0.901059  \n",
       "58   [https://docs.ray.io/en/master/data/data-inter...  0.901151  \n",
       "162  [https://docs.ray.io/en/master/genindex.html, ...  0.902390  \n",
       "113  [https://docs.ray.io/en/master/_modules/ray/tr...  0.902621  \n",
       "103  [https://docs.ray.io/en/master/ray-core/tasks....  0.902658  \n",
       "33   [https://docs.ray.io/en/master/ray-air/example...  0.902717  \n",
       "118  [https://docs.ray.io/en/master/serve/monitorin...  0.904220  \n",
       "114  [https://docs.ray.io/en/master/cluster/running...  0.904309  \n",
       "2    [https://docs.ray.io/en/master/cluster/kuberne...  0.904421  \n",
       "133  [https://docs.ray.io/en/master/ray-contribute/...  0.904679  \n",
       "79   [https://docs.ray.io/en/master/tune/examples/t...  0.904945  \n",
       "11   [https://docs.ray.io/en/master/ray-core/patter...  0.905105  \n",
       "131  [https://docs.ray.io/en/master/serve/productio...  0.905106  \n",
       "77   [https://docs.ray.io/en/master/ray-air/api/doc...  0.905477  \n",
       "50   [https://docs.ray.io/en/master/train/examples/...  0.905527  \n",
       "3    [https://docs.ray.io/en/master/cluster/faq.htm...  0.905782  \n",
       "16   [https://docs.ray.io/en/master/_modules/ray/_p...  0.906784  \n",
       "139  [https://docs.ray.io/en/master/ray-core/api/do...  0.907334  \n",
       "137  [https://docs.ray.io/en/master/ray-air/example...  0.907486  \n",
       "144  [https://docs.ray.io/en/master/ray-core/actors...  0.907727  \n",
       "65   [https://docs.ray.io/en/master/data/api/doc/ra...  0.907976  \n",
       "182  [https://docs.ray.io/en/master/cluster/metrics...  0.907976  \n",
       "112  [https://docs.ray.io/en/master/ray-observabili...  0.908137  \n",
       "27   [https://docs.ray.io/en/master/tune/tutorials/...  0.908340  \n",
       "135  [https://docs.ray.io/en/master/data/api/doc/ra...  0.909217  \n",
       "152  [https://docs.ray.io/en/master/cluster/running...  0.909391  \n",
       "142  [https://docs.ray.io/en/master/data/api/doc/ra...  0.909835  \n",
       "53   [https://docs.ray.io/en/master/ray-core/patter...  0.909935  \n",
       "166  [https://docs.ray.io/en/master/_modules/ray/se...  0.910104  \n",
       "134  [https://docs.ray.io/en/master/ray-core/api/do...  0.910245  \n",
       "115  [https://docs.ray.io/en/master/ray-core/exampl...  0.910982  \n",
       "83   [https://docs.ray.io/en/master/cluster/running...  0.911161  \n",
       "14   [https://docs.ray.io/en/master/ray-overview/ex...  0.911308  \n",
       "179  [https://docs.ray.io/en/master/serve/advanced-...  0.911450  \n",
       "37   [https://docs.ray.io/en/master/cluster/running...  0.911494  \n",
       "76   [https://docs.ray.io/en/master/ray-air/example...  0.911600  \n",
       "7    [https://docs.ray.io/en/master/ray-air/api/int...  0.911632  \n",
       "122  [https://docs.ray.io/en/master/_modules/ray/ut...  0.912331  \n",
       "74   [https://docs.ray.io/en/master/_modules/ray/_p...  0.912875  \n",
       "151  [https://docs.ray.io/en/master/ray-air/example...  0.912890  \n",
       "47   [https://docs.ray.io/en/master/data/examples/h...  0.913080  \n",
       "124  [https://docs.ray.io/en/master/ray-core/exampl...  0.913198  \n",
       "104  [https://docs.ray.io/en/master/rllib/rllib-off...  0.913383  \n",
       "126  [https://docs.ray.io/en/master/ray-observabili...  0.913574  \n",
       "109  [https://docs.ray.io/en/master/cluster/kuberne...  0.913743  \n",
       "175  [https://docs.ray.io/en/master/cluster/kuberne...  0.914214  \n",
       "96   [https://docs.ray.io/en/master/ray-core/patter...  0.914230  \n",
       "181  [https://docs.ray.io/en/master/cluster/kuberne...  0.914386  \n",
       "78   [https://docs.ray.io/en/master/ray-core/api/do...  0.914415  \n",
       "57   [https://docs.ray.io/en/master/data/api/doc/ra...  0.914495  \n",
       "91   [https://docs.ray.io/en/master/ray-core/actors...  0.914584  \n",
       "13   [https://docs.ray.io/en/master/ray-observabili...  0.915756  \n",
       "17   [https://docs.ray.io/en/master/ray-air/example...  0.916158  \n",
       "141  [https://docs.ray.io/en/master/serve/productio...  0.916743  \n",
       "43   [https://docs.ray.io/en/master/tune/examples/t...  0.916792  \n",
       "105  [https://docs.ray.io/en/master/ray-core/api/do...  0.917161  \n",
       "106  [https://docs.ray.io/en/master/ray-core/namesp...  0.917462  \n",
       "40   [https://docs.ray.io/en/master/_modules/ray/tu...  0.917809  \n",
       "64   [https://docs.ray.io/en/master/ray-core/api/do...  0.917950  \n",
       "9    [https://docs.ray.io/en/master/ray-core/actors...  0.918007  \n",
       "19   [https://docs.ray.io/en/master/serve/develop-a...  0.918046  \n",
       "147  [https://docs.ray.io/en/master/_modules/ray/_p...  0.918125  \n",
       "39   [https://docs.ray.io/en/master/cluster/faq.htm...  0.918205  \n",
       "102  [https://docs.ray.io/en/master/serve/productio...  0.918840  \n",
       "127  [https://docs.ray.io/en/master/ray-overview/ge...  0.919166  \n",
       "156  [https://docs.ray.io/en/master/ray-observabili...  0.919186  \n",
       "32   [https://docs.ray.io/en/master/_modules/ray/rl...  0.919340  \n",
       "157  [https://docs.ray.io/en/master/serve/productio...  0.919560  \n",
       "35   [https://docs.ray.io/en/master/_modules/ray/tr...  0.919909  \n",
       "61   [https://docs.ray.io/en/master/data/examples/n...  0.920008  \n",
       "75   [https://docs.ray.io/en/master/cluster/running...  0.920224  \n",
       "31   [https://docs.ray.io/en/master/ray-contribute/...  0.920602  \n",
       "123  [https://docs.ray.io/en/master/data/overview.h...  0.920639  \n",
       "160  [https://docs.ray.io/en/master/serve/productio...  0.921096  \n",
       "73   [https://docs.ray.io/en/master/_modules/ray/tr...  0.921326  \n",
       "150  [https://docs.ray.io/en/master/_modules/ray/_p...  0.921482  \n",
       "70   [https://docs.ray.io/en/master/ray-air/example...  0.921666  \n",
       "94   [https://docs.ray.io/en/master/_modules/ray/_p...  0.921710  \n",
       "22   [https://docs.ray.io/en/master/tune/api/doc/ra...  0.921728  \n",
       "164  [https://docs.ray.io/en/master/ray-observabili...  0.921751  \n",
       "165  [https://docs.ray.io/en/master/serve/api/doc/r...  0.923006  \n",
       "82   [https://docs.ray.io/en/master/ray-core/schedu...  0.923007  \n",
       "149  [https://docs.ray.io/en/master/cluster/kuberne...  0.923084  \n",
       "97   [https://docs.ray.io/en/master/ray-core/actors...  0.923596  \n",
       "140  [https://docs.ray.io/en/master/ray-observabili...  0.924051  \n",
       "59   [https://docs.ray.io/en/master/_modules/ray/ru...  0.924726  \n",
       "108  [https://docs.ray.io/en/master/ray-core/tips-f...  0.924990  \n",
       "24   [https://docs.ray.io/en/master/serve/develop-a...  0.925041  \n",
       "100  [https://docs.ray.io/en/master/ray-observabili...  0.925198  \n",
       "0    [https://docs.ray.io/en/master/_modules/ray/da...  0.925697  \n",
       "95   [https://docs.ray.io/en/master/ray-core/tips-f...  0.925720  \n",
       "84   [https://docs.ray.io/en/master/serve/productio...  0.926384  \n",
       "120  [https://docs.ray.io/en/master/ray-core/tasks....  0.926734  \n",
       "158  [https://docs.ray.io/en/master/cluster/configu...  0.926969  \n",
       "101  [https://docs.ray.io/en/master/ray-observabili...  0.928757  \n",
       "89   [https://docs.ray.io/en/master/serve/tutorials...  0.928836  \n",
       "72   [https://docs.ray.io/en/master/cluster/kuberne...  0.928879  \n",
       "167  [https://docs.ray.io/en/master/serve/scaling-a...  0.928892  \n",
       "145  [https://docs.ray.io/en/master/ray-observabili...  0.929030  \n",
       "48   [https://docs.ray.io/en/master/cluster/cli.htm...  0.929098  \n",
       "154  [https://docs.ray.io/en/master/cluster/vms/use...  0.929503  \n",
       "29   [https://docs.ray.io/en/master/ray-references/...  0.930895  \n",
       "188  [https://docs.ray.io/en/master/cluster/kuberne...  0.931484  \n",
       "60   [https://docs.ray.io/en/master/ray-core/api/do...  0.932492  \n",
       "69   [https://docs.ray.io/en/master/ray-core/exampl...  0.933479  \n",
       "86   [https://docs.ray.io/en/master/ray-overview/in...  0.933494  \n",
       "85   [https://docs.ray.io/en/master/ray-more-libs/i...  0.934124  \n",
       "136  [https://docs.ray.io/en/master/data/api/doc/ra...  0.934144  \n",
       "110  [https://docs.ray.io/en/master/cluster/kuberne...  0.936190  \n",
       "28   [https://docs.ray.io/en/master/data/api/doc/ra...  0.936484  \n",
       "49   [https://docs.ray.io/en/master/ray-air/example...  0.938923  \n",
       "121  [https://docs.ray.io/en/master/ray-observabili...  0.938978  \n",
       "44   [https://docs.ray.io/en/master/_modules/ray/tu...  0.939239  \n",
       "90   [https://docs.ray.io/en/master/_modules/ray/ac...  0.941243  \n",
       "168  [https://docs.ray.io/en/master/serve/scaling-a...  0.942521  \n",
       "52   [https://docs.ray.io/en/master/tune/tutorials/...  0.944248  \n",
       "56   [https://docs.ray.io/en/master/data/api/doc/ra...  0.944631  \n",
       "143  [https://docs.ray.io/en/master/tune/tutorials/...  0.947279  \n",
       "1    [https://docs.ray.io/en/master/serve/scaling-a...  0.949477  \n",
       "55   [https://docs.ray.io/en/master/data/api/doc/ra...  0.951803  \n",
       "12   [https://docs.ray.io/en/master/cluster/running...  0.959641  \n",
       "36   [https://docs.ray.io/en/master/serve/api/doc/r...  0.967734  \n",
       "184  [https://docs.ray.io/en/master/ray-core/walkth...  0.989103  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +8h18m39s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +8h23m39s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +8h28m39s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h3m44s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h8m44s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h13m44s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h18m45s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h23m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h28m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h33m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h38m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h43m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h48m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h53m50s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +9h58m56s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h3m56s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h8m56s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h13m56s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h18m56s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h23m56s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h29m1s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h34m1s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h39m1s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h44m1s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h49m1s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h54m1s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +10h59m2s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h4m7s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h9m7s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h14m7s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h19m8s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h24m9s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h29m9s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h34m11s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n",
      "\u001b[2m\u001b[1m\u001b[36m(autoscaler +11h39m15s)\u001b[0m [workspace snapshot] New snapshot created successfully (size: 35.40 MB).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_records(records)\n",
    "# df[\"num\"] = df[\"question\"].str.len()\n",
    "# df.corr(numeric_only=True)\n",
    "pd.set_option('display.max_rows', len(df))\n",
    "df.sort_values(by=[\"corr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9256965196597495"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DB_CONNECTION_STRING\"]=\"dbname=postgres user=postgres host=localhost password=postgres\"\n",
    "agent = QueryAgent()\n",
    "records = [{\"question\": result[\"question\"], \"targets\": 0 if result[\"score\"] < 4 else 1} for result in data[\"results\"]]\n",
    "record = records[0]\n",
    "embedding = np.array(agent.embedding_model.embed_query(record[\"question\"]))\n",
    "with agent.conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT * FROM document ORDER BY embedding <-> %s LIMIT 5\", (embedding,))\n",
    "    rows = cur.fetchall()\n",
    "np.dot(rows[0][3], embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-evaluation for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import openai\n",
    "\n",
    "def generate_response(llm, system_content, assistant_content, user_content, max_retries=3, retry_interval=60):\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                    model=llm,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_content},\n",
    "                        {\"role\": \"assistant\", \"content\": assistant_content},\n",
    "                        {\"role\": \"user\", \"content\": user_content},\n",
    "                    ])\n",
    "            return response[\"choices\"][-1][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            time.sleep(retry_interval)  # default is per-minute rate limits\n",
    "            retry_count += 1\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(llm, system_content, assistant_content, user_content, max_retries, retry_interval)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_content\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[1;32m    141\u001b[0m         timeout,\n\u001b[1;32m    142\u001b[0m         stream,\n\u001b[1;32m    143\u001b[0m         headers,\n\u001b[1;32m    144\u001b[0m         request_timeout,\n\u001b[1;32m    145\u001b[0m         typed_api_type,\n\u001b[1;32m    146\u001b[0m         requestor,\n\u001b[1;32m    147\u001b[0m         url,\n\u001b[1;32m    148\u001b[0m         params,\n\u001b[0;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[1;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[0;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[0;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[1;32m    107\u001b[0m     api_key,\n\u001b[1;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[1;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[1;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[1;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/api_requestor.py:138\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[0;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[0;32m--> 138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m     ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m api_type\n\u001b[1;32m    142\u001b[0m     \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[1;32m    143\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/openai/util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m assistant_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m user_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_content\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(llm, system_content, assistant_content, user_content, max_retries, retry_interval)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m (e)\n\u001b[0;32m---> 19\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_interval\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# default is per-minute rate limits\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         retry_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text(content, custom_html_tag=None):\n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    # default tags\n",
    "    html_tags = [\n",
    "        (\"div\", {\"role\": \"main\"}),\n",
    "        (\"main\", {\"id\": \"main-content\"}),\n",
    "    ]\n",
    "\n",
    "    if custom_html_tag is not None:\n",
    "        html_tags.append(custom_html_tag)\n",
    "\n",
    "    text = None\n",
    "\n",
    "    # reversed order. check the custom one first\n",
    "    for tag, attrs in html_tags[::-1]:\n",
    "        text = soup.find(tag, attrs)\n",
    "        # if found, break\n",
    "        if text is not None:\n",
    "            break\n",
    "\n",
    "    if text is not None:\n",
    "        text = text.get_text()\n",
    "    else:\n",
    "        text = \"\"\n",
    "    # trim empty lines\n",
    "    return \"\\n\".join([t for t in text.split(\"\\n\") if t])\n",
    "\n",
    "llm = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "\n",
    "def score_own_answer(record):\n",
    "    query = record[\"question\"]\n",
    "    source = record[\"source\"]\n",
    "    # source = \"https://docs.ray.io/en/master/data/transforming-data.html#configuring-batch-format\"\n",
    "    if source.startswith(\"https://docs.ray.io\"):\n",
    "        url = urlparse(source)\n",
    "        response = requests.get(source)\n",
    "        custom_html_tag = (\"section\", {\"id\": url.fragment}) if url.fragment else None\n",
    "        context = extract_text(response.content, custom_html_tag)\n",
    "    else:\n",
    "        context = \"\"\n",
    "\n",
    "    system_content = \"Answer the {query} using the additional {context} provided.\".format(query=query, context=context)\n",
    "    assistant_content = \"\"\n",
    "    user_content = \"\"\n",
    "\n",
    "    answer = generate_response(llm, system_content, assistant_content, user_content)\n",
    "\n",
    "    system_content += \"\\n \" + answer + \"\\n Your job is to rate the quality of the answer above.\\n Your score has to be between 1 and 5.\\n You must return your response in a line with only the score.\\n Do not return answers in any other format.\"\n",
    "\n",
    "    record[\"rating\"] = generate_response(llm, system_content, assistant_content, user_content)\n",
    "\n",
    "with open(Path(ROOT_DIR, \"datasets/eval-dataset-v1.jsonl\")) as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "\n",
    "for record in records:\n",
    "    score_own_answer(record)\n",
    "    print(record)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
